{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the library.\n",
    "ee.Initialize(project='ee-earthdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import datetime\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Define the geometry for contiguous USA\n",
    "usa_coords = [\n",
    "    [-125.1803892906456, 35.26328285844432],\n",
    "    [-117.08916345892665, 33.2311514593429],\n",
    "    [-114.35640058749676, 32.92199940444295],\n",
    "    [-110.88773544819885, 31.612036247094473],\n",
    "    [-108.91086200144109, 31.7082477979397],\n",
    "    [-106.80030780089378, 32.42079476218232],\n",
    "    [-103.63413436750255, 29.786401496314422],\n",
    "    [-101.87558377066483, 30.622527701868453],\n",
    "    [-99.40039768482492, 28.04018292597704],\n",
    "    [-98.69085295525215, 26.724810345780593],\n",
    "    [-96.42355704777482, 26.216515704595633],\n",
    "    [-80.68508661702214, 24.546812350183075],\n",
    "    [-75.56173032587596, 26.814533788629998],\n",
    "    [-67.1540159827795, 44.40095539443753],\n",
    "    [-68.07548734644243, 46.981170472447374],\n",
    "    [-69.17500995805074, 46.98158998130476],\n",
    "    [-70.7598785138901, 44.87172183866657],\n",
    "    [-74.84994741250935, 44.748084983808],\n",
    "    [-77.62168256782745, 43.005725611950055],\n",
    "    [-82.45987924104175, 41.41068867019324],\n",
    "    [-83.38318501671864, 42.09979904377044],\n",
    "    [-82.5905167831457, 45.06163491639556],\n",
    "    [-84.83301910769038, 46.83552648258547],\n",
    "    [-88.26350848510909, 48.143646480291835],\n",
    "    [-90.06706251069104, 47.553445811024204],\n",
    "    [-95.03745451438925, 48.9881557770297],\n",
    "    [-98.45773319567587, 48.94699366043251],\n",
    "    [-101.7018751401119, 48.98284560308372],\n",
    "    [-108.43164852530356, 48.81973606668503],\n",
    "    [-115.07339190755627, 48.93699058308441],\n",
    "    [-121.82530604190744, 48.9830983403776],\n",
    "    [-122.22085227110232, 48.63535795404536],\n",
    "    [-124.59504332589562, 47.695726563030405],\n",
    "    [-125.1803892906456, 35.26328285844432]\n",
    "]\n",
    "\n",
    "def create_usa_geometry():\n",
    "    \"\"\"Create an Earth Engine geometry object for the contiguous USA.\"\"\"\n",
    "    return ee.Geometry.Polygon([usa_coords])\n",
    "\n",
    "def compute_area(feature):\n",
    "    \"\"\"Compute the area of a feature and set it as a property.\"\"\"\n",
    "    return feature.set({'area': feature.area()})\n",
    "\n",
    "def compute_centroid(feature):\n",
    "    \"\"\"Compute the centroid coordinates of a feature and set them as properties.\"\"\"\n",
    "    centroid = feature.geometry().centroid().coordinates()\n",
    "    return feature.set({\n",
    "        'lon': centroid.get(0),\n",
    "        'lat': centroid.get(1)\n",
    "    })\n",
    "\n",
    "def compute_date(feature):\n",
    "    \"\"\"Set start and end dates as properties of a feature.\"\"\"\n",
    "    return feature.set({\n",
    "        'start_date': ee.Date(feature.get('IDate')),\n",
    "        'end_date': ee.Date(feature.get('FDate'))\n",
    "    })\n",
    "\n",
    "def ee_array_to_df(arr, list_of_bands):\n",
    "    \"\"\"Convert Earth Engine array to pandas DataFrame.\"\"\"\n",
    "    df = pd.DataFrame(arr)\n",
    "    \n",
    "    # Select subset of columns if list_of_bands is not empty\n",
    "    if list_of_bands:\n",
    "        df = df[list_of_bands]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def ee_featurecollection_to_gdf(fc):\n",
    "    \"\"\"Convert Earth Engine FeatureCollection to GeoPandas DataFrame.\"\"\"\n",
    "    features = fc.getInfo()['features']\n",
    "    \n",
    "    # Extract the geometry and properties from each feature\n",
    "    geometries = []\n",
    "    properties = []\n",
    "    \n",
    "    for feature in features:\n",
    "        # Convert GEE geometry to Shapely geometry\n",
    "        geom = feature['geometry']\n",
    "        if geom['type'] == 'Polygon':\n",
    "            geometry = Polygon(geom['coordinates'][0])\n",
    "        else:\n",
    "            # Handle other geometry types if needed\n",
    "            continue\n",
    "            \n",
    "        geometries.append(geometry)\n",
    "        properties.append(feature['properties'])\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    df = pd.DataFrame(properties)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Convert timestamps to datetime\n",
    "    if 'IDate' in gdf.columns:\n",
    "        gdf['start_date'] = pd.to_datetime(gdf['IDate'].min(), unit='ms')\n",
    "        gdf['end_date'] = pd.to_datetime(gdf['IDate'].max(), unit='ms')\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def get_fires(year, min_size=1e7):\n",
    "    \"\"\"\n",
    "    Get fires from the GlobFire database for a specific year and minimum size.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to filter fires for\n",
    "        min_size (float): Minimum fire size in square meters (default: 1e7)\n",
    "    \n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: GeoDataFrame containing fire data\n",
    "    \"\"\"\n",
    "    # Create geometry\n",
    "    geometry = create_usa_geometry()\n",
    "    \n",
    "    # Create date range for the year\n",
    "    start_date = ee.Date(f'{year}-01-01')\n",
    "    end_date = ee.Date(f'{year}-12-31')\n",
    "    \n",
    "    # Get and filter fire polygons\n",
    "    polygons = (ee.FeatureCollection('JRC/GWIS/GlobFire/v2/FinalPerimeters')\n",
    "                .filter(ee.Filter.gt('IDate', start_date.millis()))\n",
    "                .filter(ee.Filter.lt('IDate', end_date.millis()))\n",
    "                .filterBounds(geometry))\n",
    "    \n",
    "    # Apply area calculations and filters\n",
    "    polygons = polygons.map(compute_area)\n",
    "    polygons = (polygons\n",
    "                .filter(ee.Filter.gt('area', min_size))\n",
    "                .filter(ee.Filter.lt('area', 1e20)))\n",
    "    \n",
    "    # Compute additional properties\n",
    "    polygons = polygons.map(compute_centroid).map(compute_date)\n",
    "    \n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = ee_featurecollection_to_gdf(polygons)\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    YEAR = \"2018\"\n",
    "    MIN_SIZE = 1e7  # 1 square kilometers\n",
    "    \n",
    "    # Get fires as a GeoDataFrame\n",
    "    fires_gdf = get_fires(YEAR, MIN_SIZE)\n",
    "    \n",
    "    print(f\"Retrieved {len(fires_gdf)} fires for {YEAR}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(fires_gdf.head())\n",
    "    \n",
    "    # Example: Basic statistics\n",
    "    print(\"\\nArea statistics (square meters):\")\n",
    "    print(fires_gdf['area'].describe())\n",
    "    \n",
    "    # # Example: Save to file\n",
    "    # output_file = f\"us_fires_{YEAR}.gpkg\"\n",
    "    # fires_gdf.to_file(output_file, driver=\"GPKG\")\n",
    "    # print(f\"\\nSaved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download GlobFire Daily Fire Event Detection Based on MCD64A1 using Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import datetime\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Define the geometry for contiguous USA\n",
    "usa_coords = [\n",
    "    [-125.1803892906456, 35.26328285844432],\n",
    "    [-117.08916345892665, 33.2311514593429],\n",
    "    [-114.35640058749676, 32.92199940444295],\n",
    "    [-110.88773544819885, 31.612036247094473],\n",
    "    [-108.91086200144109, 31.7082477979397],\n",
    "    [-106.80030780089378, 32.42079476218232],\n",
    "    [-103.63413436750255, 29.786401496314422],\n",
    "    [-101.87558377066483, 30.622527701868453],\n",
    "    [-99.40039768482492, 28.04018292597704],\n",
    "    [-98.69085295525215, 26.724810345780593],\n",
    "    [-96.42355704777482, 26.216515704595633],\n",
    "    [-80.68508661702214, 24.546812350183075],\n",
    "    [-75.56173032587596, 26.814533788629998],\n",
    "    [-67.1540159827795, 44.40095539443753],\n",
    "    [-68.07548734644243, 46.981170472447374],\n",
    "    [-69.17500995805074, 46.98158998130476],\n",
    "    [-70.7598785138901, 44.87172183866657],\n",
    "    [-74.84994741250935, 44.748084983808],\n",
    "    [-77.62168256782745, 43.005725611950055],\n",
    "    [-82.45987924104175, 41.41068867019324],\n",
    "    [-83.38318501671864, 42.09979904377044],\n",
    "    [-82.5905167831457, 45.06163491639556],\n",
    "    [-84.83301910769038, 46.83552648258547],\n",
    "    [-88.26350848510909, 48.143646480291835],\n",
    "    [-90.06706251069104, 47.553445811024204],\n",
    "    [-95.03745451438925, 48.9881557770297],\n",
    "    [-98.45773319567587, 48.94699366043251],\n",
    "    [-101.7018751401119, 48.98284560308372],\n",
    "    [-108.43164852530356, 48.81973606668503],\n",
    "    [-115.07339190755627, 48.93699058308441],\n",
    "    [-121.82530604190744, 48.9830983403776],\n",
    "    [-122.22085227110232, 48.63535795404536],\n",
    "    [-124.59504332589562, 47.695726563030405],\n",
    "    [-125.1803892906456, 35.26328285844432]\n",
    "]\n",
    "\n",
    "def create_usa_geometry():\n",
    "    \"\"\"Create an Earth Engine geometry object for the contiguous USA.\"\"\"\n",
    "    return ee.Geometry.Polygon([usa_coords])\n",
    "\n",
    "def compute_area(feature):\n",
    "    \"\"\"Compute the area of a feature and set it as a property.\"\"\"\n",
    "    return feature.set({'area': feature.area()})\n",
    "\n",
    "def compute_centroid(feature):\n",
    "    \"\"\"Compute the centroid coordinates of a feature and set them as properties.\"\"\"\n",
    "    centroid = feature.geometry().centroid().coordinates()\n",
    "    return feature.set({\n",
    "        'lon': centroid.get(0),\n",
    "        'lat': centroid.get(1)\n",
    "    })\n",
    "\n",
    "def ee_featurecollection_to_gdf(fc):\n",
    "    \"\"\"Convert Earth Engine FeatureCollection to GeoPandas DataFrame.\"\"\"\n",
    "    features = fc.getInfo()['features']\n",
    "    \n",
    "    # Extract the geometry and properties from each feature\n",
    "    geometries = []\n",
    "    properties = []\n",
    "    \n",
    "    for feature in features:\n",
    "        # Convert GEE geometry to Shapely geometry\n",
    "        geom = feature['geometry']\n",
    "        if geom['type'] == 'Polygon':\n",
    "            geometry = Polygon(geom['coordinates'][0])\n",
    "        else:\n",
    "            # Handle other geometry types if needed\n",
    "            continue\n",
    "            \n",
    "        geometries.append(geometry)\n",
    "        properties.append(feature['properties'])\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    df = pd.DataFrame(properties)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Convert area to numeric\n",
    "    if 'area' in gdf.columns:\n",
    "        gdf['area'] = pd.to_numeric(gdf['area'])\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def get_daily_fires(year, min_size=1e7, region=None):\n",
    "    \"\"\"\n",
    "    Get daily fire perimeters from the GlobFire database for a specific year and minimum size.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to get fires for\n",
    "        min_size (float): Minimum fire size in square meters (default: 1e7)\n",
    "        region (ee.Geometry, optional): Region to filter fires. Defaults to contiguous USA.\n",
    "    \n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: GeoDataFrame containing daily fire perimeter data\n",
    "    \"\"\"\n",
    "    # Set up region\n",
    "    if region is None:\n",
    "        region = create_usa_geometry()\n",
    "    \n",
    "    # Create collection name for the specified year\n",
    "    collection_name = f'JRC/GWIS/GlobFire/v2/DailyPerimeters/{year}'\n",
    "    \n",
    "    try:\n",
    "        # Get and filter fire polygons\n",
    "        polygons = (ee.FeatureCollection(collection_name)\n",
    "                   .filterBounds(region))\n",
    "        \n",
    "        # Apply area calculations and filters\n",
    "        polygons = polygons.map(compute_area)\n",
    "        polygons = (polygons\n",
    "                   .filter(ee.Filter.gt('area', min_size))\n",
    "                   .filter(ee.Filter.lt('area', 1e20)))\n",
    "        \n",
    "        # Compute additional properties\n",
    "        polygons = polygons.map(compute_centroid)\n",
    "        \n",
    "        # Convert to GeoDataFrame\n",
    "        gdf = ee_featurecollection_to_gdf(polygons)\n",
    "        \n",
    "        # Add date column if not present\n",
    "        if 'date' not in gdf.columns:\n",
    "            gdf['date'] = pd.to_datetime(gdf['IDate'], unit='ms')\n",
    "        \n",
    "        return gdf\n",
    "        \n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(f\"Error accessing collection for year {year}: {str(e)}\")\n",
    "        print(\"Note: Daily perimeters might not be available for this year.\")\n",
    "        return None\n",
    "\n",
    "def analyze_daily_fires(gdf):\n",
    "    \"\"\"\n",
    "    Perform basic analysis on the daily fire perimeters.\n",
    "    \n",
    "    Args:\n",
    "        gdf (geopandas.GeoDataFrame): GeoDataFrame containing fire data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing analysis results\n",
    "    \"\"\"\n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        return None\n",
    "        \n",
    "    analysis = {\n",
    "        'total_fires': len(gdf),\n",
    "        'total_area_km2': gdf['area'].sum() / 1e6,  # Convert to km²\n",
    "        'mean_area_km2': gdf['area'].mean() / 1e6,\n",
    "        'max_area_km2': gdf['area'].max() / 1e6,\n",
    "        'date_range': f\"{gdf['IDate'].min()} to {gdf['IDate'].max()}\"\n",
    "    }\n",
    "    \n",
    "    if 'fid' in gdf.columns:\n",
    "        analysis['unique_fires'] = gdf['fid'].nunique()\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    YEAR = \"2020\"\n",
    "    MIN_SIZE = 1e7  # 10 square kilometers\n",
    "    \n",
    "    # Get daily fire perimeters as a GeoDataFrame\n",
    "    fires_gdf = get_daily_fires(YEAR, MIN_SIZE)\n",
    "    \n",
    "    if fires_gdf is not None:\n",
    "        # Perform basic analysis\n",
    "        analysis_results = analyze_daily_fires(fires_gdf)\n",
    "        \n",
    "        print(f\"\\nAnalysis Results for {YEAR}:\")\n",
    "        for key, value in analysis_results.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        \n",
    "        # # Example: Save to file\n",
    "        # output_file = f\"us_daily_fires_{YEAR}.gpkg\"\n",
    "        # fires_gdf.to_file(output_file, driver=\"GPKG\")\n",
    "        # print(f\"\\nSaved to {output_file}\")\n",
    "        \n",
    "        # Example: Show temporal distribution\n",
    "        print(\"\\nFires by month:\")\n",
    "        monthly_counts = fires_gdf.groupby(fires_gdf['date'].dt.month).size()\n",
    "        print(monthly_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fires_gdf[fires_gdf['Id'] == 24332628])):\n",
    "    fires_gdf[fires_gdf['Id'] == 24332628].sort_values('IDate').iloc[i].geometry.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop everything that does not have at least 2 Id in fires_gdf\n",
    "fires_gdf_reduced = fires_gdf[fires_gdf['Id'].isin(fires_gdf['Id'].value_counts()[fires_gdf['Id'].value_counts() > 1].index)]# save to geojson\n",
    "fires_gdf_reduced.to_file(f\"data/perims/combined_fires_{YEAR}.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download daily and final perims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import datetime\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Define the geometry for contiguous USA\n",
    "usa_coords = [\n",
    "    [-125.1803892906456, 35.26328285844432],\n",
    "    [-117.08916345892665, 33.2311514593429],\n",
    "    [-114.35640058749676, 32.92199940444295],\n",
    "    [-110.88773544819885, 31.612036247094473],\n",
    "    [-108.91086200144109, 31.7082477979397],\n",
    "    [-106.80030780089378, 32.42079476218232],\n",
    "    [-103.63413436750255, 29.786401496314422],\n",
    "    [-101.87558377066483, 30.622527701868453],\n",
    "    [-99.40039768482492, 28.04018292597704],\n",
    "    [-98.69085295525215, 26.724810345780593],\n",
    "    [-96.42355704777482, 26.216515704595633],\n",
    "    [-80.68508661702214, 24.546812350183075],\n",
    "    [-75.56173032587596, 26.814533788629998],\n",
    "    [-67.1540159827795, 44.40095539443753],\n",
    "    [-68.07548734644243, 46.981170472447374],\n",
    "    [-69.17500995805074, 46.98158998130476],\n",
    "    [-70.7598785138901, 44.87172183866657],\n",
    "    [-74.84994741250935, 44.748084983808],\n",
    "    [-77.62168256782745, 43.005725611950055],\n",
    "    [-82.45987924104175, 41.41068867019324],\n",
    "    [-83.38318501671864, 42.09979904377044],\n",
    "    [-82.5905167831457, 45.06163491639556],\n",
    "    [-84.83301910769038, 46.83552648258547],\n",
    "    [-88.26350848510909, 48.143646480291835],\n",
    "    [-90.06706251069104, 47.553445811024204],\n",
    "    [-95.03745451438925, 48.9881557770297],\n",
    "    [-98.45773319567587, 48.94699366043251],\n",
    "    [-101.7018751401119, 48.98284560308372],\n",
    "    [-108.43164852530356, 48.81973606668503],\n",
    "    [-115.07339190755627, 48.93699058308441],\n",
    "    [-121.82530604190744, 48.9830983403776],\n",
    "    [-122.22085227110232, 48.63535795404536],\n",
    "    [-124.59504332589562, 47.695726563030405],\n",
    "    [-125.1803892906456, 35.26328285844432]\n",
    "]\n",
    "\n",
    "def create_usa_geometry():\n",
    "    \"\"\"Create an Earth Engine geometry object for the contiguous USA.\"\"\"\n",
    "    return ee.Geometry.Polygon([usa_coords])\n",
    "\n",
    "def compute_area(feature):\n",
    "    \"\"\"Compute the area of a feature and set it as a property.\"\"\"\n",
    "    return feature.set({'area': feature.area()})\n",
    "\n",
    "def compute_centroid(feature):\n",
    "    \"\"\"Compute the centroid coordinates of a feature and set them as properties.\"\"\"\n",
    "    centroid = feature.geometry().centroid().coordinates()\n",
    "    return feature.set({\n",
    "        'lon': centroid.get(0),\n",
    "        'lat': centroid.get(1)\n",
    "    })\n",
    "\n",
    "def ee_featurecollection_to_gdf(fc):\n",
    "    \"\"\"Convert Earth Engine FeatureCollection to GeoPandas DataFrame.\"\"\"\n",
    "    features = fc.getInfo()['features']\n",
    "    \n",
    "    # Extract the geometry and properties from each feature\n",
    "    geometries = []\n",
    "    properties = []\n",
    "    \n",
    "    for feature in features:\n",
    "        # Convert GEE geometry to Shapely geometry\n",
    "        geom = feature['geometry']\n",
    "        if geom['type'] == 'Polygon':\n",
    "            geometry = Polygon(geom['coordinates'][0])\n",
    "        else:\n",
    "            # Handle other geometry types if needed\n",
    "            continue\n",
    "            \n",
    "        geometries.append(geometry)\n",
    "        properties.append(feature['properties'])\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    df = pd.DataFrame(properties)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Convert area to numeric\n",
    "    if 'area' in gdf.columns:\n",
    "        gdf['area'] = pd.to_numeric(gdf['area'])\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def get_daily_fires(year, min_size=1e7, region=None):\n",
    "    \"\"\"\n",
    "    Get daily fire perimeters from the GlobFire database.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to get fires for\n",
    "        min_size (float): Minimum fire size in square meters\n",
    "        region (ee.Geometry, optional): Region to filter fires\n",
    "    \"\"\"\n",
    "    if region is None:\n",
    "        region = create_usa_geometry()\n",
    "    \n",
    "    collection_name = f'JRC/GWIS/GlobFire/v2/DailyPerimeters/{year}'\n",
    "    \n",
    "    try:\n",
    "        polygons = (ee.FeatureCollection(collection_name)\n",
    "                   .filterBounds(region))\n",
    "        \n",
    "        polygons = polygons.map(compute_area)\n",
    "        polygons = (polygons\n",
    "                   .filter(ee.Filter.gt('area', min_size))\n",
    "                   .filter(ee.Filter.lt('area', 1e20)))\n",
    "        \n",
    "        polygons = polygons.map(compute_centroid)\n",
    "        \n",
    "        gdf = ee_featurecollection_to_gdf(polygons)\n",
    "        \n",
    "        if not gdf.empty:\n",
    "            gdf['source'] = 'daily'\n",
    "            # Convert IDate to datetime directly for each row\n",
    "            gdf['date'] = pd.to_datetime(gdf['IDate'], unit='ms')\n",
    "            # For daily perimeters, end_date is same as start date\n",
    "            gdf['end_date'] = gdf['date']\n",
    "        \n",
    "        return gdf\n",
    "        \n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(f\"Error accessing daily collection for {year}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_final_fires(year, min_size=1e7, region=None):\n",
    "    \"\"\"\n",
    "    Get final fire perimeters from the GlobFire database.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to get fires for\n",
    "        min_size (float): Minimum fire size in square meters\n",
    "        region (ee.Geometry, optional): Region to filter fires\n",
    "    \"\"\"\n",
    "    if region is None:\n",
    "        region = create_usa_geometry()\n",
    "    \n",
    "    start_date = ee.Date(f'{year}-01-01')\n",
    "    end_date = ee.Date(f'{year}-12-31')\n",
    "    \n",
    "    try:\n",
    "        polygons = (ee.FeatureCollection('JRC/GWIS/GlobFire/v2/FinalPerimeters')\n",
    "                   .filter(ee.Filter.gt('IDate', start_date.millis()))\n",
    "                   .filter(ee.Filter.lt('IDate', end_date.millis()))\n",
    "                   .filterBounds(region))\n",
    "        \n",
    "        polygons = polygons.map(compute_area)\n",
    "        polygons = (polygons\n",
    "                   .filter(ee.Filter.gt('area', min_size))\n",
    "                   .filter(ee.Filter.lt('area', 1e20)))\n",
    "        \n",
    "        polygons = polygons.map(compute_centroid)\n",
    "        \n",
    "        gdf = ee_featurecollection_to_gdf(polygons)\n",
    "        \n",
    "        if not gdf.empty:\n",
    "            gdf['source'] = 'final'\n",
    "            # Convert IDate and FDate to datetime for each row\n",
    "            gdf['date'] = pd.to_datetime(gdf['IDate'], unit='ms')\n",
    "            gdf['end_date'] = pd.to_datetime(gdf['FDate'], unit='ms')\n",
    "        \n",
    "        return gdf\n",
    "        \n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(f\"Error accessing final perimeters for {year}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_combined_fires(year, min_size=1e7, region=None):\n",
    "    \"\"\"\n",
    "    Get both daily and final fire perimeters and combine them based on Id.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to get fires for\n",
    "        min_size (float): Minimum fire size in square meters\n",
    "        region (ee.Geometry, optional): Region to filter fires\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (combined_gdf, daily_gdf, final_gdf)\n",
    "    \"\"\"\n",
    "    daily_gdf = get_daily_fires(year, min_size, region)\n",
    "    final_gdf = get_final_fires(year, min_size, region)\n",
    "    \n",
    "    if daily_gdf is None and final_gdf is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Ensure we have dataframes to work with\n",
    "    if daily_gdf is None:\n",
    "        daily_gdf = gpd.GeoDataFrame()\n",
    "    if final_gdf is None:\n",
    "        final_gdf = gpd.GeoDataFrame()\n",
    "    \n",
    "    # Convert timestamps consistently\n",
    "    for gdf in [daily_gdf, final_gdf]:\n",
    "        if not gdf.empty:\n",
    "            # Convert all timestamp fields to numeric if they aren't already\n",
    "            for col in ['IDate', 'FDate']:\n",
    "                if col in gdf.columns:\n",
    "                    gdf[col] = pd.to_numeric(gdf[col])\n",
    "            for col in ['FDate']:\n",
    "                if col in gdf.columns:\n",
    "                    gdf[col] = gdf['end_date']\n",
    "    \n",
    "    # Get unique fire IDs\n",
    "    all_ids = pd.concat([\n",
    "        daily_gdf['Id'] if not daily_gdf.empty else pd.Series(dtype=int),\n",
    "        final_gdf['Id'] if not final_gdf.empty else pd.Series(dtype=int)\n",
    "    ]).unique()\n",
    "    \n",
    "    combined_data = []\n",
    "    \n",
    "    for fire_id in all_ids:\n",
    "        # Get daily perimeters for this fire\n",
    "        daily_fire = daily_gdf[daily_gdf['Id'] == fire_id] if not daily_gdf.empty else None\n",
    "        # Get final perimeter for this fire\n",
    "        final_fire = final_gdf[final_gdf['Id'] == fire_id] if not final_gdf.empty else None\n",
    "        \n",
    "        if daily_fire is not None and not daily_fire.empty:\n",
    "            # Add all daily perimeters\n",
    "            combined_data.append(daily_fire)\n",
    "        \n",
    "        if final_fire is not None and not final_fire.empty:\n",
    "            # Add final perimeter\n",
    "            combined_data.append(final_fire)\n",
    "    \n",
    "    if not combined_data:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_gdf = pd.concat(combined_data, ignore_index=True)\n",
    "    \n",
    "    # Sort by Id and date for consistency\n",
    "    combined_gdf = combined_gdf.sort_values(['Id', 'date'])\n",
    "    \n",
    "    return combined_gdf, daily_gdf, final_gdf\n",
    "\n",
    "def analyze_fires(gdf):\n",
    "    \"\"\"\n",
    "    Perform basic analysis on fire perimeters.\n",
    "    \"\"\"\n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Basic statistics\n",
    "    stats = {\n",
    "        'total_fires': len(gdf),\n",
    "        'unique_fires': gdf['Id'].nunique(),\n",
    "        'total_area_km2': gdf['area'].sum() / 1e6,\n",
    "        'mean_area_km2': gdf['area'].mean() / 1e6,\n",
    "        'max_area_km2': gdf['area'].max() / 1e6,\n",
    "        'date_range': f\"{gdf['date'].min()} to {gdf['end_date'].max()}\"\n",
    "    }\n",
    "    \n",
    "    # Add source-specific counts\n",
    "    if 'source' in gdf.columns:\n",
    "        source_counts = gdf['source'].value_counts()\n",
    "        for source in source_counts.index:\n",
    "            stats[f'{source}_fires'] = source_counts[source]\n",
    "            \n",
    "        # Add counts of fires with both daily and final perimeters\n",
    "        fires_with_both = (gdf.groupby('Id')['source']\n",
    "                          .nunique()\n",
    "                          .where(lambda x: x > 1)\n",
    "                          .count())\n",
    "        stats['fires_with_both_perims'] = fires_with_both\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Example usage\n",
    "YEAR = \"2020\"\n",
    "MIN_SIZE = 1e7  # 10 square kilometers\n",
    "\n",
    "# Get both daily and final perimeters\n",
    "combined_gdf, daily_gdf, final_gdf = get_combined_fires(YEAR, MIN_SIZE)\n",
    "\n",
    "if combined_gdf is not None:\n",
    "    print(f\"\\nAnalysis Results for {YEAR}:\")\n",
    "    \n",
    "    print(\"\\nCombined Perimeters:\")\n",
    "    combined_stats = analyze_fires(combined_gdf)\n",
    "    for key, value in combined_stats.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    if daily_gdf is not None:\n",
    "        print(\"\\nDaily Perimeters:\")\n",
    "        daily_stats = analyze_fires(daily_gdf)\n",
    "        for key, value in daily_stats.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    if final_gdf is not None:\n",
    "        print(\"\\nFinal Perimeters:\")\n",
    "        final_stats = analyze_fires(final_gdf)\n",
    "        for key, value in final_stats.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Temporal distribution\n",
    "    print(\"\\nFires by month:\")\n",
    "    monthly_counts = combined_gdf.groupby([combined_gdf['date'].dt.month, 'source']).size().unstack(fill_value=0)\n",
    "    print(monthly_counts)\n",
    "\n",
    "# drop everything that does not have at least 2 Id in combined_gdf\n",
    "combined_gdf_reduced = combined_gdf[combined_gdf['Id'].isin(combined_gdf['Id'].value_counts()[combined_gdf['Id'].value_counts() > 1].index)]# save to geojson\n",
    "combined_gdf_reduced.to_file(f\"data/perims/combined_fires_{YEAR}.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_perimeters(daily_gdf, final_gdf):\n",
    "    \"\"\"\n",
    "    Create a dataframe containing only fire perimeters that appear in both daily and final datasets.\n",
    "    \n",
    "    Args:\n",
    "        daily_gdf (GeoDataFrame): DataFrame containing daily fire perimeters\n",
    "        final_gdf (GeoDataFrame): DataFrame containing final fire perimeters\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: Combined DataFrame containing only fires that appear in both datasets\n",
    "    \"\"\"\n",
    "    # Handle cases where either dataframe is None or empty\n",
    "    if daily_gdf is None or final_gdf is None or daily_gdf.empty or final_gdf.empty:\n",
    "        return None\n",
    "    \n",
    "    # Get IDs that appear in both datasets\n",
    "    daily_ids = set(daily_gdf['Id'].unique())\n",
    "    final_ids = set(final_gdf['Id'].unique())\n",
    "    matching_ids = daily_ids.intersection(final_ids)\n",
    "    \n",
    "    if not matching_ids:\n",
    "        return None\n",
    "    \n",
    "    # Filter both dataframes for matching IDs\n",
    "    daily_matches = daily_gdf[daily_gdf['Id'].isin(matching_ids)].copy()\n",
    "    final_matches = final_gdf[final_gdf['Id'].isin(matching_ids)].copy()\n",
    "    \n",
    "    # Combine the filtered dataframes\n",
    "    matching_perims = pd.concat([daily_matches, final_matches], ignore_index=True)\n",
    "    \n",
    "    # Sort by Id and date for consistency\n",
    "    matching_perims = matching_perims.sort_values(['Id', 'date'])\n",
    "    \n",
    "    # Add some useful metadata\n",
    "    matching_perims['match_type'] = 'both_sources'\n",
    "    \n",
    "    return matching_perims\n",
    "\n",
    "# Example usage in main script:\n",
    "if __name__ == \"__main__\":\n",
    "    YEAR = \"2020\"\n",
    "    MIN_SIZE = 1e7  # 10 square kilometers\n",
    "    \n",
    "    # Get fire perimeters\n",
    "    # combined_gdf, daily_gdf, final_gdf = get_combined_fires(YEAR, MIN_SIZE)\n",
    "    \n",
    "    # Get matching perimeters\n",
    "    matching_perims = get_matching_perimeters(daily_gdf, final_gdf)\n",
    "    \n",
    "    if matching_perims is not None:\n",
    "        print(\"\\nMatching Perimeters Analysis:\")\n",
    "        matching_stats = analyze_fires(matching_perims)\n",
    "        for key, value in matching_stats.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "            \n",
    "        # Additional statistics specific to matching perimeters\n",
    "        print(\"\\nDetailed Matching Statistics:\")\n",
    "        unique_matches = matching_perims['Id'].nunique()\n",
    "        print(f\"Number of unique fires with both daily and final perimeters: {unique_matches}\")\n",
    "        \n",
    "        # Calculate average number of daily perims per fire\n",
    "        daily_counts = matching_perims[matching_perims['source'] == 'daily'].groupby('Id').size()\n",
    "        print(f\"Average daily perimeters per fire: {daily_counts.mean():.1f}\")\n",
    "        print(f\"Max daily perimeters for a single fire: {daily_counts.max()}\")\n",
    "        \n",
    "        # Show distribution of time spans\n",
    "        time_spans = matching_perims.groupby('Id').agg({\n",
    "            'date': 'min',\n",
    "            'end_date': 'max'\n",
    "        })\n",
    "        time_spans['duration_days'] = (time_spans['end_date'] - time_spans['date']).dt.total_seconds() / (24*3600)\n",
    "        print(f\"\\nFire duration statistics (days):\")\n",
    "        print(f\"Mean duration: {time_spans['duration_days'].mean():.1f}\")\n",
    "        print(f\"Median duration: {time_spans['duration_days'].median():.1f}\")\n",
    "        print(f\"Max duration: {time_spans['duration_days'].max():.1f}\")\n",
    "    else:\n",
    "        print(\"\\nNo matching perimeters found between daily and final datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_gdf[combined_gdf.Id == 25294714]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show Ids that match between daily and final as keys in a dict, with the number of times they appear in daily source as values\n",
    "fires = {}\n",
    "for i in final_gdf['Id']:\n",
    "    if i in daily_gdf['Id'].values:\n",
    "        fires[i] = daily_gdf[daily_gdf['Id'] == i].shape[0]\n",
    "\n",
    "fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the perims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "def calculate_area_km2(geometry, lat, lon):\n",
    "    \"\"\"\n",
    "    Calculate area in square kilometers using an equal area projection.\n",
    "    \n",
    "    Args:\n",
    "        geometry: Shapely geometry\n",
    "        lat: Latitude of centroid for projection center\n",
    "        lon: Longitude of centroid for projection center\n",
    "    \n",
    "    Returns:\n",
    "        float: Area in square kilometers\n",
    "    \"\"\"\n",
    "    # Create a temporary GeoDataFrame with the geometry\n",
    "    temp_gdf = gpd.GeoDataFrame(geometry=[geometry], crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Project to an equal area projection centered on the area of interest\n",
    "    proj_string = f\"+proj=aea +lat_1={lat-5} +lat_2={lat+5} +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\n",
    "    temp_gdf = temp_gdf.to_crs(proj_string)\n",
    "    \n",
    "    # Calculate area in km²\n",
    "    return temp_gdf.area.iloc[0] / 1e6\n",
    "\n",
    "def get_polygon_coords(geometry):\n",
    "    \"\"\"\n",
    "    Extract coordinates from either a Polygon or MultiPolygon.\n",
    "    Returns a list of coordinate arrays, one per ring.\n",
    "    \"\"\"\n",
    "    coords_list = []\n",
    "    \n",
    "    if isinstance(geometry, MultiPolygon):\n",
    "        for polygon in geometry.geoms:\n",
    "            coords_list.append(np.array(polygon.exterior.coords))\n",
    "            for interior in polygon.interiors:\n",
    "                coords_list.append(np.array(interior.coords))\n",
    "    elif isinstance(geometry, Polygon):\n",
    "        coords_list.append(np.array(geometry.exterior.coords))\n",
    "        for interior in geometry.interiors:\n",
    "            coords_list.append(np.array(interior.coords))\n",
    "    \n",
    "    return coords_list\n",
    "\n",
    "def animate_fire_progression(gdf, fire_id, interval=500):\n",
    "    \"\"\"\n",
    "    Create an animated visualization of cumulative fire progression.\n",
    "    \"\"\"\n",
    "    # Filter for the specific fire and sort by date\n",
    "    fire_perimeters = gdf[gdf['Id'] == fire_id].sort_values('IDate')\n",
    "    \n",
    "    # Pre-compute cumulative geometries\n",
    "    cumulative_geometries = []\n",
    "    current_geometry = None\n",
    "    \n",
    "    for idx, row in fire_perimeters.iterrows():\n",
    "        if current_geometry is None:\n",
    "            current_geometry = row.geometry\n",
    "        else:\n",
    "            current_geometry = unary_union([current_geometry, row.geometry])\n",
    "        cumulative_geometries.append(current_geometry)\n",
    "    \n",
    "    # Get centroid of final perimeter for area calculation\n",
    "    final_centroid = cumulative_geometries[-1].centroid\n",
    "    \n",
    "    # Create GeoDataFrame with cumulative geometries\n",
    "    cumulative_gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            'geometry': cumulative_geometries,\n",
    "            'IDate': fire_perimeters['IDate'].values\n",
    "        },\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    # Calculate areas using the centroid-based projection\n",
    "    cumulative_gdf['area_km2'] = [\n",
    "        calculate_area_km2(geom, final_centroid.y, final_centroid.x)\n",
    "        for geom in cumulative_gdf.geometry\n",
    "    ]\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Set consistent plot limits\n",
    "    total_bounds = cumulative_gdf.total_bounds\n",
    "    padding = 0.1\n",
    "    width = total_bounds[2] - total_bounds[0]\n",
    "    height = total_bounds[3] - total_bounds[1]\n",
    "    ax.set_xlim(total_bounds[0] - width * padding, \n",
    "                total_bounds[2] + width * padding)\n",
    "    ax.set_ylim(total_bounds[1] - height * padding, \n",
    "                total_bounds[3] + height * padding)\n",
    "    \n",
    "    # Create lists to store all lines and fills\n",
    "    lines = []\n",
    "    fills = []\n",
    "    \n",
    "    # Initialize with empty data\n",
    "    for i in range(10):\n",
    "        line, = ax.plot([], [], 'r-', lw=2)\n",
    "        fill = ax.fill([], [], 'r', alpha=0.3)[0]\n",
    "        lines.append(line)\n",
    "        fills.append(fill)\n",
    "    \n",
    "    area_text = ax.text(0.02, 0.98, '', transform=ax.transAxes, \n",
    "                       verticalalignment='top')\n",
    "    title = ax.set_title('')\n",
    "    \n",
    "    # Format dates for display\n",
    "    dates = pd.to_datetime(cumulative_gdf['IDate'], unit='ms')\n",
    "    date_strings = dates.dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    def init():\n",
    "        for line, fill in zip(lines, fills):\n",
    "            line.set_data([], [])\n",
    "            fill.set_xy(np.empty((0, 2)))\n",
    "        area_text.set_text('')\n",
    "        return lines + fills + [area_text, title]\n",
    "    \n",
    "    def animate(frame):\n",
    "        perimeter = cumulative_gdf.iloc[frame]\n",
    "        all_coords = get_polygon_coords(perimeter.geometry)\n",
    "        \n",
    "        for i, coords in enumerate(all_coords):\n",
    "            if i < len(lines):\n",
    "                lines[i].set_data(coords[:, 0], coords[:, 1])\n",
    "                fills[i].set_xy(coords)\n",
    "            else:\n",
    "                line, = ax.plot([], [], 'r-', lw=2)\n",
    "                fill = ax.fill([], [], 'r', alpha=0.3)[0]\n",
    "                lines.append(line)\n",
    "                fills.append(fill)\n",
    "                lines[i].set_data(coords[:, 0], coords[:, 1])\n",
    "                fills[i].set_xy(coords)\n",
    "        \n",
    "        for i in range(len(all_coords), len(lines)):\n",
    "            lines[i].set_data([], [])\n",
    "            fills[i].set_xy(np.empty((0, 2)))\n",
    "        \n",
    "        area_text.set_text(f'Area: {perimeter.area_km2:.2f} km²')\n",
    "        title.set_text(f'Fire ID {fire_id} - {date_strings.iloc[frame]}')\n",
    "        \n",
    "        return lines + fills + [area_text, title]\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                 frames=len(cumulative_gdf),\n",
    "                                 interval=interval, blit=True)\n",
    "    \n",
    "    html = anim.to_jshtml()\n",
    "    plt.close()\n",
    "    \n",
    "    return HTML(html)\n",
    "\n",
    "def create_fire_summary(gdf, fire_id):\n",
    "    \"\"\"\n",
    "    Create a summary of cumulative fire progression.\n",
    "    \"\"\"\n",
    "    fire_perimeters = gdf[gdf['Id'] == fire_id].sort_values('IDate')\n",
    "    \n",
    "    # Calculate cumulative geometries\n",
    "    cumulative_geometries = []\n",
    "    current_geometry = None\n",
    "    \n",
    "    for idx, row in fire_perimeters.iterrows():\n",
    "        if current_geometry is None:\n",
    "            current_geometry = row.geometry\n",
    "        else:\n",
    "            current_geometry = unary_union([current_geometry, row.geometry])\n",
    "        cumulative_geometries.append(current_geometry)\n",
    "    \n",
    "    # Get centroid of final perimeter for area calculation\n",
    "    final_centroid = cumulative_geometries[-1].centroid\n",
    "    \n",
    "    # Calculate areas\n",
    "    areas = [\n",
    "        calculate_area_km2(geom, final_centroid.y, final_centroid.x)\n",
    "        for geom in cumulative_geometries\n",
    "    ]\n",
    "    \n",
    "    # Convert dates\n",
    "    dates = pd.to_datetime(fire_perimeters['IDate'], unit='ms')\n",
    "    \n",
    "    summary = {\n",
    "        'start_date': dates.min(),\n",
    "        'end_date': dates.max(),\n",
    "        'duration_days': (dates.max() - dates.min()).days,\n",
    "        'num_updates': len(fire_perimeters),\n",
    "        'initial_area_km2': areas[0],\n",
    "        'final_area_km2': areas[-1],\n",
    "        'total_growth_km2': areas[-1] - areas[0],\n",
    "        'average_daily_growth_km2': (areas[-1] - areas[0]) / max((dates.max() - dates.min()).days, 1)\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Create and display the animation\n",
    "animation = animate_fire_progression(fires_gdf, 24332801)\n",
    "display(animation)\n",
    "\n",
    "# Get summary statistics\n",
    "summary = create_fire_summary(fires_gdf, 24332801)\n",
    "print(\"\\nFire Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "def calculate_area_km2(geometry, lat, lon):\n",
    "    \"\"\"\n",
    "    Calculate area in square kilometers using an equal area projection.\n",
    "    \"\"\"\n",
    "    temp_gdf = gpd.GeoDataFrame(geometry=[geometry], crs=\"EPSG:4326\")\n",
    "    proj_string = f\"+proj=aea +lat_1={lat-5} +lat_2={lat+5} +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\n",
    "    temp_gdf = temp_gdf.to_crs(proj_string)\n",
    "    return temp_gdf.area.iloc[0] / 1e6\n",
    "\n",
    "def get_polygon_coords(geometry):\n",
    "    \"\"\"\n",
    "    Extract coordinates from either a Polygon or MultiPolygon.\n",
    "    \"\"\"\n",
    "    coords_list = []\n",
    "    if isinstance(geometry, MultiPolygon):\n",
    "        for polygon in geometry.geoms:\n",
    "            coords_list.append(np.array(polygon.exterior.coords))\n",
    "            for interior in polygon.interiors:\n",
    "                coords_list.append(np.array(interior.coords))\n",
    "    elif isinstance(geometry, Polygon):\n",
    "        coords_list.append(np.array(geometry.exterior.coords))\n",
    "        for interior in geometry.interiors:\n",
    "            coords_list.append(np.array(interior.coords))\n",
    "    return coords_list\n",
    "\n",
    "def animate_fire_progression(gdf, fire_id, interval=500):\n",
    "    \"\"\"\n",
    "    Create an animated visualization of fire progression with final perimeter.\n",
    "    \"\"\"\n",
    "    # Split daily and final perimeters\n",
    "    daily_perims = gdf[(gdf['Id'] == fire_id) & (gdf['source'] == 'daily')].sort_values('date')\n",
    "    final_perim = gdf[(gdf['Id'] == fire_id) & (gdf['source'] == 'final')]\n",
    "    \n",
    "    # Pre-compute daily cumulative geometries\n",
    "    cumulative_geometries = []\n",
    "    current_geometry = None\n",
    "    \n",
    "    for idx, row in daily_perims.iterrows():\n",
    "        if current_geometry is None:\n",
    "            current_geometry = row.geometry\n",
    "        else:\n",
    "            current_geometry = unary_union([current_geometry, row.geometry])\n",
    "        cumulative_geometries.append(current_geometry)\n",
    "    \n",
    "    # Add final perimeter as the last frame if it exists\n",
    "    if not final_perim.empty:\n",
    "        cumulative_geometries.append(final_perim.iloc[0].geometry)\n",
    "        # For daily perimeters, use 'date', for final perimeter use 'end_date'\n",
    "        dates = pd.concat([\n",
    "            daily_perims['date'],\n",
    "            pd.Series([final_perim.iloc[0]['end_date']])\n",
    "        ]).reset_index(drop=True)\n",
    "    else:\n",
    "        dates = daily_perims['date'].reset_index(drop=True)\n",
    "    \n",
    "    # Get centroid of final perimeter for area calculation\n",
    "    final_centroid = cumulative_geometries[-1].centroid\n",
    "    \n",
    "    # Create GeoDataFrame with cumulative geometries\n",
    "    cumulative_gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            'geometry': cumulative_geometries,\n",
    "            'date': dates,\n",
    "            'is_final': [False] * len(daily_perims) + [True] * (1 if not final_perim.empty else 0)\n",
    "        },\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    # Calculate areas\n",
    "    cumulative_gdf['area_km2'] = [\n",
    "        calculate_area_km2(geom, final_centroid.y, final_centroid.x)\n",
    "        for geom in cumulative_gdf.geometry\n",
    "    ]\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Set consistent plot limits\n",
    "    total_bounds = cumulative_gdf.total_bounds\n",
    "    padding = 0.1\n",
    "    width = total_bounds[2] - total_bounds[0]\n",
    "    height = total_bounds[3] - total_bounds[1]\n",
    "    ax.set_xlim(total_bounds[0] - width * padding, \n",
    "                total_bounds[2] + width * padding)\n",
    "    ax.set_ylim(total_bounds[1] - height * padding, \n",
    "                total_bounds[3] + height * padding)\n",
    "    \n",
    "    # Create lists to store all lines and fills\n",
    "    lines = []\n",
    "    fills = []\n",
    "    \n",
    "    # Initialize with empty data\n",
    "    for i in range(10):\n",
    "        line, = ax.plot([], [], 'r-', lw=2)\n",
    "        fill = ax.fill([], [], 'r', alpha=0.3)[0]\n",
    "        lines.append(line)\n",
    "        fills.append(fill)\n",
    "    \n",
    "    area_text = ax.text(0.02, 0.98, '', transform=ax.transAxes, \n",
    "                       verticalalignment='top')\n",
    "    title = ax.set_title('')\n",
    "    \n",
    "    def init():\n",
    "        for line, fill in zip(lines, fills):\n",
    "            line.set_data([], [])\n",
    "            fill.set_xy(np.empty((0, 2)))\n",
    "        area_text.set_text('')\n",
    "        return lines + fills + [area_text, title]\n",
    "    \n",
    "    def animate(frame):\n",
    "        perimeter = cumulative_gdf.iloc[frame]\n",
    "        all_coords = get_polygon_coords(perimeter.geometry)\n",
    "        \n",
    "        # Use different colors for final perimeter\n",
    "        color = 'blue' if perimeter.is_final else 'r'\n",
    "        alpha = 0.5 if perimeter.is_final else 0.3\n",
    "        \n",
    "        for i, coords in enumerate(all_coords):\n",
    "            if i < len(lines):\n",
    "                lines[i].set_color(color)\n",
    "                lines[i].set_data(coords[:, 0], coords[:, 1])\n",
    "                fills[i].set_facecolor(color)\n",
    "                fills[i].set_alpha(alpha)\n",
    "                fills[i].set_xy(coords)\n",
    "            else:\n",
    "                line, = ax.plot([], [], f'{color}-', lw=2)\n",
    "                fill = ax.fill([], [], color, alpha=alpha)[0]\n",
    "                lines.append(line)\n",
    "                fills.append(fill)\n",
    "                lines[i].set_data(coords[:, 0], coords[:, 1])\n",
    "                fills[i].set_xy(coords)\n",
    "        \n",
    "        for i in range(len(all_coords), len(lines)):\n",
    "            lines[i].set_data([], [])\n",
    "            fills[i].set_xy(np.empty((0, 2)))\n",
    "        \n",
    "        # Update area text\n",
    "        area_text.set_text(f'Area: {perimeter.area_km2:.2f} km²')\n",
    "        \n",
    "        # Update title with date and type\n",
    "        perim_type = \"Final Perimeter\" if perimeter.is_final else \"Daily Perimeter\"\n",
    "        display_date = perimeter.date.strftime(\"%Y-%m-%d\")\n",
    "        title.set_text(f'Fire ID {fire_id} - {display_date} ({perim_type})')\n",
    "        \n",
    "        return lines + fills + [area_text, title]\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                 frames=len(cumulative_gdf),\n",
    "                                 interval=interval, blit=True)\n",
    "    \n",
    "    html = anim.to_jshtml()\n",
    "    plt.close()\n",
    "    \n",
    "    return HTML(html)\n",
    "\n",
    "def create_fire_summary(gdf, fire_id):\n",
    "    \"\"\"\n",
    "    Create a summary of fire progression including both daily and final perimeters.\n",
    "    \"\"\"\n",
    "    # Get daily perimeters and optional final perimeter\n",
    "    daily_perims = gdf[(gdf['Id'] == fire_id) & (gdf['source'] == 'daily')].sort_values('date')\n",
    "    final_perim = gdf[(gdf['Id'] == fire_id) & (gdf['source'] == 'final')]\n",
    "    \n",
    "    # Calculate cumulative geometries for daily progression\n",
    "    cumulative_geometries = []\n",
    "    current_geometry = None\n",
    "    \n",
    "    for idx, row in daily_perims.iterrows():\n",
    "        if current_geometry is None:\n",
    "            current_geometry = row.geometry\n",
    "        else:\n",
    "            current_geometry = unary_union([current_geometry, row.geometry])\n",
    "        cumulative_geometries.append(current_geometry)\n",
    "    \n",
    "    # Add final perimeter if available\n",
    "    if not final_perim.empty:\n",
    "        final_geometry = final_perim.iloc[0].geometry\n",
    "        final_date = final_perim.iloc[0].end_date\n",
    "    else:\n",
    "        final_geometry = cumulative_geometries[-1] if cumulative_geometries else None\n",
    "        final_date = daily_perims.iloc[-1].end_date if not daily_perims.empty else None\n",
    "    \n",
    "    if not cumulative_geometries and final_geometry is None:\n",
    "        return None\n",
    "    \n",
    "    # Get centroid for area calculations\n",
    "    centroid = final_geometry.centroid if final_geometry else cumulative_geometries[-1].centroid\n",
    "    \n",
    "    # Calculate areas\n",
    "    daily_areas = [\n",
    "        calculate_area_km2(geom, centroid.y, centroid.x)\n",
    "        for geom in cumulative_geometries\n",
    "    ]\n",
    "    \n",
    "    if final_geometry:\n",
    "        final_area = calculate_area_km2(final_geometry, centroid.y, centroid.x)\n",
    "    else:\n",
    "        final_area = daily_areas[-1] if daily_areas else None\n",
    "    \n",
    "    # Get dates\n",
    "    start_date = daily_perims.iloc[0].end_date if not daily_perims.empty else final_date\n",
    "    \n",
    "    summary = {\n",
    "        'start_date': start_date,\n",
    "        'end_date': final_date,\n",
    "        'duration_days': (final_date - start_date).days,\n",
    "        'num_daily_updates': len(daily_perims),\n",
    "        'has_final_perimeter': not final_perim.empty,\n",
    "        'initial_area_km2': daily_areas[0] if daily_areas else final_area,\n",
    "        'final_area_km2': final_area,\n",
    "        'total_growth_km2': final_area - daily_areas[0] if daily_areas else 0,\n",
    "        'average_daily_growth_km2': (final_area - daily_areas[0]) / max((final_date - start_date).days, 1) if daily_areas else 0\n",
    "    }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display the animation\n",
    "# animation = None\n",
    "animation = animate_fire_progression(combined_gdf, 20778153)\n",
    "display(animation)\n",
    "\n",
    "# Get summary statistics\n",
    "summary = create_fire_summary(combined_gdf, 20778153)\n",
    "print(\"\\nFire Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop everything that does not have at least 2 Id in combined_gdf\n",
    "combined_gdf_reduced = combined_gdf[combined_gdf['Id'].isin(combined_gdf['Id'].value_counts()[combined_gdf['Id'].value_counts() > 1].index)]# save to geojson\n",
    "combined_gdf_reduced.to_file(f\"data/perims/combined_fires_{YEAR}.geojson\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
