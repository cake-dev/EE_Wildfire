{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/drive%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=CI9QwSyPn0BbsGcWyJKIlSGEkdG12EjZ1IfHqWUcup0&tc=sNIAqrrLLCMxhHRBpdk8lkRO_X-FxEOxdDE4dXDkGvY&cc=VLbWFZ0qpOyTvQiIlfeahTY045kHa3SHwuHPf8x0y9A>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/drive%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=CI9QwSyPn0BbsGcWyJKIlSGEkdG12EjZ1IfHqWUcup0&tc=sNIAqrrLLCMxhHRBpdk8lkRO_X-FxEOxdDE4dXDkGvY&cc=VLbWFZ0qpOyTvQiIlfeahTY045kHa3SHwuHPf8x0y9A</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "\n",
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the library.\n",
    "ee.Initialize(project='ee-earthdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 202 fires for 2018\n",
      "\n",
      "First few rows:\n",
      "           FDate          IDate        Id          area  \\\n",
      "0  1534809604096  1533859201024  21999351  1.481149e+07   \n",
      "1  1535587200000  1533859201024  21999273  1.760197e+07   \n",
      "2  1524528000000  1523318400000  21695137  1.137694e+07   \n",
      "3  1535328000000  1534636800000  22000460  1.824607e+07   \n",
      "4  1535068800000  1533600000000  21999354  2.382719e+07   \n",
      "\n",
      "                 end_date        lat         lon start_date  \\\n",
      "0 2018-12-27 00:00:04.096  45.146409 -111.887149 2018-01-05   \n",
      "1 2018-12-27 00:00:04.096  48.636841 -118.153748 2018-01-05   \n",
      "2 2018-12-27 00:00:04.096  48.806488  -94.938775 2018-01-05   \n",
      "3 2018-12-27 00:00:04.096  48.373018  -95.372592 2018-01-05   \n",
      "4 2018-12-27 00:00:04.096  45.001859 -111.834084 2018-01-05   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((-111.89699 45.15833, -111.91472 45.1...  \n",
      "1  POLYGON ((-118.14388 48.61667, -118.13758 48.6...  \n",
      "2  POLYGON ((-94.94708 48.79583, -94.93443 48.795...  \n",
      "3  POLYGON ((-95.37985 48.36667, -95.37205 48.362...  \n",
      "4  POLYGON ((-111.85674 44.97500, -111.86852 44.9...  \n",
      "\n",
      "Area statistics (square meters):\n",
      "count    2.020000e+02\n",
      "mean     4.244506e+07\n",
      "std      8.440642e+07\n",
      "min      1.008882e+07\n",
      "25%      1.223557e+07\n",
      "50%      1.674342e+07\n",
      "75%      2.892538e+07\n",
      "max      8.979191e+08\n",
      "Name: area, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import datetime\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "# ee.Initialize()\n",
    "\n",
    "# Define the geometry for contiguous USA\n",
    "usa_coords = [\n",
    "    [-125.1803892906456, 35.26328285844432],\n",
    "    [-117.08916345892665, 33.2311514593429],\n",
    "    [-114.35640058749676, 32.92199940444295],\n",
    "    [-110.88773544819885, 31.612036247094473],\n",
    "    [-108.91086200144109, 31.7082477979397],\n",
    "    [-106.80030780089378, 32.42079476218232],\n",
    "    [-103.63413436750255, 29.786401496314422],\n",
    "    [-101.87558377066483, 30.622527701868453],\n",
    "    [-99.40039768482492, 28.04018292597704],\n",
    "    [-98.69085295525215, 26.724810345780593],\n",
    "    [-96.42355704777482, 26.216515704595633],\n",
    "    [-80.68508661702214, 24.546812350183075],\n",
    "    [-75.56173032587596, 26.814533788629998],\n",
    "    [-67.1540159827795, 44.40095539443753],\n",
    "    [-68.07548734644243, 46.981170472447374],\n",
    "    [-69.17500995805074, 46.98158998130476],\n",
    "    [-70.7598785138901, 44.87172183866657],\n",
    "    [-74.84994741250935, 44.748084983808],\n",
    "    [-77.62168256782745, 43.005725611950055],\n",
    "    [-82.45987924104175, 41.41068867019324],\n",
    "    [-83.38318501671864, 42.09979904377044],\n",
    "    [-82.5905167831457, 45.06163491639556],\n",
    "    [-84.83301910769038, 46.83552648258547],\n",
    "    [-88.26350848510909, 48.143646480291835],\n",
    "    [-90.06706251069104, 47.553445811024204],\n",
    "    [-95.03745451438925, 48.9881557770297],\n",
    "    [-98.45773319567587, 48.94699366043251],\n",
    "    [-101.7018751401119, 48.98284560308372],\n",
    "    [-108.43164852530356, 48.81973606668503],\n",
    "    [-115.07339190755627, 48.93699058308441],\n",
    "    [-121.82530604190744, 48.9830983403776],\n",
    "    [-122.22085227110232, 48.63535795404536],\n",
    "    [-124.59504332589562, 47.695726563030405],\n",
    "    [-125.1803892906456, 35.26328285844432]\n",
    "]\n",
    "\n",
    "def create_usa_geometry():\n",
    "    \"\"\"Create an Earth Engine geometry object for the contiguous USA.\"\"\"\n",
    "    return ee.Geometry.Polygon([usa_coords])\n",
    "\n",
    "def compute_area(feature):\n",
    "    \"\"\"Compute the area of a feature and set it as a property.\"\"\"\n",
    "    return feature.set({'area': feature.area()})\n",
    "\n",
    "def compute_centroid(feature):\n",
    "    \"\"\"Compute the centroid coordinates of a feature and set them as properties.\"\"\"\n",
    "    centroid = feature.geometry().centroid().coordinates()\n",
    "    return feature.set({\n",
    "        'lon': centroid.get(0),\n",
    "        'lat': centroid.get(1)\n",
    "    })\n",
    "\n",
    "def compute_date(feature):\n",
    "    \"\"\"Set start and end dates as properties of a feature.\"\"\"\n",
    "    return feature.set({\n",
    "        'start_date': ee.Date(feature.get('IDate')),\n",
    "        'end_date': ee.Date(feature.get('FDate'))\n",
    "    })\n",
    "\n",
    "def ee_array_to_df(arr, list_of_bands):\n",
    "    \"\"\"Convert Earth Engine array to pandas DataFrame.\"\"\"\n",
    "    df = pd.DataFrame(arr)\n",
    "    \n",
    "    # Select subset of columns if list_of_bands is not empty\n",
    "    if list_of_bands:\n",
    "        df = df[list_of_bands]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def ee_featurecollection_to_gdf(fc):\n",
    "    \"\"\"Convert Earth Engine FeatureCollection to GeoPandas DataFrame.\"\"\"\n",
    "    features = fc.getInfo()['features']\n",
    "    \n",
    "    # Extract the geometry and properties from each feature\n",
    "    geometries = []\n",
    "    properties = []\n",
    "    \n",
    "    for feature in features:\n",
    "        # Convert GEE geometry to Shapely geometry\n",
    "        geom = feature['geometry']\n",
    "        if geom['type'] == 'Polygon':\n",
    "            geometry = Polygon(geom['coordinates'][0])\n",
    "        else:\n",
    "            # Handle other geometry types if needed\n",
    "            continue\n",
    "            \n",
    "        geometries.append(geometry)\n",
    "        properties.append(feature['properties'])\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    df = pd.DataFrame(properties)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Convert timestamps to datetime\n",
    "    if 'IDate' in gdf.columns:\n",
    "        gdf['start_date'] = pd.to_datetime(gdf['IDate'].min(), unit='ms')\n",
    "        gdf['end_date'] = pd.to_datetime(gdf['IDate'].max(), unit='ms')\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def get_fires(year, min_size=1e7):\n",
    "    \"\"\"\n",
    "    Get fires from the GlobFire database for a specific year and minimum size.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to filter fires for\n",
    "        min_size (float): Minimum fire size in square meters (default: 1e7)\n",
    "    \n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: GeoDataFrame containing fire data\n",
    "    \"\"\"\n",
    "    # Create geometry\n",
    "    geometry = create_usa_geometry()\n",
    "    \n",
    "    # Create date range for the year\n",
    "    start_date = ee.Date(f'{year}-01-01')\n",
    "    end_date = ee.Date(f'{year}-12-31')\n",
    "    \n",
    "    # Get and filter fire polygons\n",
    "    polygons = (ee.FeatureCollection('JRC/GWIS/GlobFire/v2/FinalPerimeters')\n",
    "                .filter(ee.Filter.gt('IDate', start_date.millis()))\n",
    "                .filter(ee.Filter.lt('IDate', end_date.millis()))\n",
    "                .filterBounds(geometry))\n",
    "    \n",
    "    # Apply area calculations and filters\n",
    "    polygons = polygons.map(compute_area)\n",
    "    polygons = (polygons\n",
    "                .filter(ee.Filter.gt('area', min_size))\n",
    "                .filter(ee.Filter.lt('area', 1e20)))\n",
    "    \n",
    "    # Compute additional properties\n",
    "    polygons = polygons.map(compute_centroid).map(compute_date)\n",
    "    \n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = ee_featurecollection_to_gdf(polygons)\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    YEAR = \"2018\"\n",
    "    MIN_SIZE = 1e7  # 1 square kilometers\n",
    "    \n",
    "    # Get fires as a GeoDataFrame\n",
    "    fires_gdf = get_fires(YEAR, MIN_SIZE)\n",
    "    \n",
    "    print(f\"Retrieved {len(fires_gdf)} fires for {YEAR}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(fires_gdf.head())\n",
    "    \n",
    "    # Example: Basic statistics\n",
    "    print(\"\\nArea statistics (square meters):\")\n",
    "    print(fires_gdf['area'].describe())\n",
    "    \n",
    "    # # Example: Save to file\n",
    "    # output_file = f\"us_fires_{YEAR}.gpkg\"\n",
    "    # fires_gdf.to_file(output_file, driver=\"GPKG\")\n",
    "    # print(f\"\\nSaved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download GlobFire Daily Fire Event Detection Based on MCD64A1 using Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Results for 2020:\n",
      "total_fires: 467\n",
      "total_area_km2: 13743.735363573065\n",
      "mean_area_km2: 29.429840178957313\n",
      "max_area_km2: 553.8236206000157\n",
      "date_range: 1579507200000 to 1606982400000\n",
      "\n",
      "Fires by month:\n",
      "date\n",
      "1       1\n",
      "2       2\n",
      "3      23\n",
      "4      38\n",
      "5       8\n",
      "6      48\n",
      "7      29\n",
      "8     122\n",
      "9     181\n",
      "10     14\n",
      "12      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import datetime\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "# ee.Initialize()\n",
    "\n",
    "# Define the geometry for contiguous USA\n",
    "usa_coords = [\n",
    "    [-125.1803892906456, 35.26328285844432],\n",
    "    [-117.08916345892665, 33.2311514593429],\n",
    "    [-114.35640058749676, 32.92199940444295],\n",
    "    [-110.88773544819885, 31.612036247094473],\n",
    "    [-108.91086200144109, 31.7082477979397],\n",
    "    [-106.80030780089378, 32.42079476218232],\n",
    "    [-103.63413436750255, 29.786401496314422],\n",
    "    [-101.87558377066483, 30.622527701868453],\n",
    "    [-99.40039768482492, 28.04018292597704],\n",
    "    [-98.69085295525215, 26.724810345780593],\n",
    "    [-96.42355704777482, 26.216515704595633],\n",
    "    [-80.68508661702214, 24.546812350183075],\n",
    "    [-75.56173032587596, 26.814533788629998],\n",
    "    [-67.1540159827795, 44.40095539443753],\n",
    "    [-68.07548734644243, 46.981170472447374],\n",
    "    [-69.17500995805074, 46.98158998130476],\n",
    "    [-70.7598785138901, 44.87172183866657],\n",
    "    [-74.84994741250935, 44.748084983808],\n",
    "    [-77.62168256782745, 43.005725611950055],\n",
    "    [-82.45987924104175, 41.41068867019324],\n",
    "    [-83.38318501671864, 42.09979904377044],\n",
    "    [-82.5905167831457, 45.06163491639556],\n",
    "    [-84.83301910769038, 46.83552648258547],\n",
    "    [-88.26350848510909, 48.143646480291835],\n",
    "    [-90.06706251069104, 47.553445811024204],\n",
    "    [-95.03745451438925, 48.9881557770297],\n",
    "    [-98.45773319567587, 48.94699366043251],\n",
    "    [-101.7018751401119, 48.98284560308372],\n",
    "    [-108.43164852530356, 48.81973606668503],\n",
    "    [-115.07339190755627, 48.93699058308441],\n",
    "    [-121.82530604190744, 48.9830983403776],\n",
    "    [-122.22085227110232, 48.63535795404536],\n",
    "    [-124.59504332589562, 47.695726563030405],\n",
    "    [-125.1803892906456, 35.26328285844432]\n",
    "]\n",
    "\n",
    "def create_usa_geometry():\n",
    "    \"\"\"Create an Earth Engine geometry object for the contiguous USA.\"\"\"\n",
    "    return ee.Geometry.Polygon([usa_coords])\n",
    "\n",
    "def compute_area(feature):\n",
    "    \"\"\"Compute the area of a feature and set it as a property.\"\"\"\n",
    "    return feature.set({'area': feature.area()})\n",
    "\n",
    "def compute_centroid(feature):\n",
    "    \"\"\"Compute the centroid coordinates of a feature and set them as properties.\"\"\"\n",
    "    centroid = feature.geometry().centroid().coordinates()\n",
    "    return feature.set({\n",
    "        'lon': centroid.get(0),\n",
    "        'lat': centroid.get(1)\n",
    "    })\n",
    "\n",
    "def ee_featurecollection_to_gdf(fc):\n",
    "    \"\"\"Convert Earth Engine FeatureCollection to GeoPandas DataFrame.\"\"\"\n",
    "    features = fc.getInfo()['features']\n",
    "    \n",
    "    # Extract the geometry and properties from each feature\n",
    "    geometries = []\n",
    "    properties = []\n",
    "    \n",
    "    for feature in features:\n",
    "        # Convert GEE geometry to Shapely geometry\n",
    "        geom = feature['geometry']\n",
    "        if geom['type'] == 'Polygon':\n",
    "            geometry = Polygon(geom['coordinates'][0])\n",
    "        else:\n",
    "            # Handle other geometry types if needed\n",
    "            continue\n",
    "            \n",
    "        geometries.append(geometry)\n",
    "        properties.append(feature['properties'])\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    df = pd.DataFrame(properties)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Convert area to numeric\n",
    "    if 'area' in gdf.columns:\n",
    "        gdf['area'] = pd.to_numeric(gdf['area'])\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def get_daily_fires(year, min_size=1e7, region=None):\n",
    "    \"\"\"\n",
    "    Get daily fire perimeters from the GlobFire database for a specific year and minimum size.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to get fires for\n",
    "        min_size (float): Minimum fire size in square meters (default: 1e7)\n",
    "        region (ee.Geometry, optional): Region to filter fires. Defaults to contiguous USA.\n",
    "    \n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: GeoDataFrame containing daily fire perimeter data\n",
    "    \"\"\"\n",
    "    # Set up region\n",
    "    if region is None:\n",
    "        region = create_usa_geometry()\n",
    "    \n",
    "    # Create collection name for the specified year\n",
    "    collection_name = f'JRC/GWIS/GlobFire/v2/DailyPerimeters/{year}'\n",
    "    \n",
    "    try:\n",
    "        # Get and filter fire polygons\n",
    "        polygons = (ee.FeatureCollection(collection_name)\n",
    "                   .filterBounds(region))\n",
    "        \n",
    "        # Apply area calculations and filters\n",
    "        polygons = polygons.map(compute_area)\n",
    "        polygons = (polygons\n",
    "                   .filter(ee.Filter.gt('area', min_size))\n",
    "                   .filter(ee.Filter.lt('area', 1e20)))\n",
    "        \n",
    "        # Compute additional properties\n",
    "        polygons = polygons.map(compute_centroid)\n",
    "        \n",
    "        # Convert to GeoDataFrame\n",
    "        gdf = ee_featurecollection_to_gdf(polygons)\n",
    "        \n",
    "        # Add date column if not present\n",
    "        if 'date' not in gdf.columns:\n",
    "            gdf['date'] = pd.to_datetime(gdf['IDate'], unit='ms')\n",
    "        \n",
    "        return gdf\n",
    "        \n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(f\"Error accessing collection for year {year}: {str(e)}\")\n",
    "        print(\"Note: Daily perimeters might not be available for this year.\")\n",
    "        return None\n",
    "\n",
    "def analyze_daily_fires(gdf):\n",
    "    \"\"\"\n",
    "    Perform basic analysis on the daily fire perimeters.\n",
    "    \n",
    "    Args:\n",
    "        gdf (geopandas.GeoDataFrame): GeoDataFrame containing fire data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing analysis results\n",
    "    \"\"\"\n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        return None\n",
    "        \n",
    "    analysis = {\n",
    "        'total_fires': len(gdf),\n",
    "        'total_area_km2': gdf['area'].sum() / 1e6,  # Convert to km²\n",
    "        'mean_area_km2': gdf['area'].mean() / 1e6,\n",
    "        'max_area_km2': gdf['area'].max() / 1e6,\n",
    "        'date_range': f\"{gdf['IDate'].min()} to {gdf['IDate'].max()}\"\n",
    "    }\n",
    "    \n",
    "    if 'fid' in gdf.columns:\n",
    "        analysis['unique_fires'] = gdf['fid'].nunique()\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    YEAR = \"2020\"\n",
    "    MIN_SIZE = 1e7  # 10 square kilometers\n",
    "    \n",
    "    # Get daily fire perimeters as a GeoDataFrame\n",
    "    fires_gdf = get_daily_fires(YEAR, MIN_SIZE)\n",
    "    \n",
    "    if fires_gdf is not None:\n",
    "        # Perform basic analysis\n",
    "        analysis_results = analyze_daily_fires(fires_gdf)\n",
    "        \n",
    "        print(f\"\\nAnalysis Results for {YEAR}:\")\n",
    "        for key, value in analysis_results.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        \n",
    "        # # Example: Save to file\n",
    "        # output_file = f\"us_daily_fires_{YEAR}.gpkg\"\n",
    "        # fires_gdf.to_file(output_file, driver=\"GPKG\")\n",
    "        # print(f\"\\nSaved to {output_file}\")\n",
    "        \n",
    "        # Example: Show temporal distribution\n",
    "        print(\"\\nFires by month:\")\n",
    "        monthly_counts = fires_gdf.groupby(fires_gdf['date'].dt.month).size()\n",
    "        print(monthly_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDate</th>\n",
       "      <th>Id</th>\n",
       "      <th>area</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>geometry</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1597474800000</td>\n",
       "      <td>24332989</td>\n",
       "      <td>1.008901e+07</td>\n",
       "      <td>42.269284</td>\n",
       "      <td>-115.275083</td>\n",
       "      <td>POLYGON ((-115.29725 42.28333, -115.28200 42.2...</td>\n",
       "      <td>2020-08-15 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1599894000000</td>\n",
       "      <td>24332939</td>\n",
       "      <td>4.336176e+07</td>\n",
       "      <td>44.769012</td>\n",
       "      <td>-122.367882</td>\n",
       "      <td>POLYGON ((-122.44796 44.81250, -122.43912 44.8...</td>\n",
       "      <td>2020-09-12 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1599894000000</td>\n",
       "      <td>24462488</td>\n",
       "      <td>1.094684e+07</td>\n",
       "      <td>44.152739</td>\n",
       "      <td>-122.422893</td>\n",
       "      <td>POLYGON ((-122.42098 44.17083, -122.44421 44.1...</td>\n",
       "      <td>2020-09-12 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1599894000000</td>\n",
       "      <td>24462610</td>\n",
       "      <td>2.747575e+07</td>\n",
       "      <td>43.361897</td>\n",
       "      <td>-122.926997</td>\n",
       "      <td>POLYGON ((-122.94620 43.38333, -122.96340 43.3...</td>\n",
       "      <td>2020-09-12 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1599894000000</td>\n",
       "      <td>24462610</td>\n",
       "      <td>2.575642e+07</td>\n",
       "      <td>43.331563</td>\n",
       "      <td>-122.778974</td>\n",
       "      <td>POLYGON ((-122.82007 43.38333, -122.80320 43.3...</td>\n",
       "      <td>2020-09-12 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           IDate        Id          area        lat         lon  \\\n",
       "0  1597474800000  24332989  1.008901e+07  42.269284 -115.275083   \n",
       "1  1599894000000  24332939  4.336176e+07  44.769012 -122.367882   \n",
       "2  1599894000000  24462488  1.094684e+07  44.152739 -122.422893   \n",
       "3  1599894000000  24462610  2.747575e+07  43.361897 -122.926997   \n",
       "4  1599894000000  24462610  2.575642e+07  43.331563 -122.778974   \n",
       "\n",
       "                                            geometry                date  \n",
       "0  POLYGON ((-115.29725 42.28333, -115.28200 42.2... 2020-08-15 07:00:00  \n",
       "1  POLYGON ((-122.44796 44.81250, -122.43912 44.8... 2020-09-12 07:00:00  \n",
       "2  POLYGON ((-122.42098 44.17083, -122.44421 44.1... 2020-09-12 07:00:00  \n",
       "3  POLYGON ((-122.94620 43.38333, -122.96340 43.3... 2020-09-12 07:00:00  \n",
       "4  POLYGON ((-122.82007 43.38333, -122.80320 43.3... 2020-09-12 07:00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fires_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fires_gdf[fires_gdf['Id'] == 24332628])):\n",
    "    fires_gdf[fires_gdf['Id'] == 24332628].sort_values('IDate').iloc[i].geometry.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "Failed to create GeoJSON datasource: data/perims/combined_fires_2020.geojson: data/perims/combined_fires_2020.geojson: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:175\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_create\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\\\_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: Failed to create GeoJSON datasource: data/perims/combined_fires_2020.geojson: data/perims/combined_fires_2020.geojson: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# drop everything that does not have at least 2 Id in fires_gdf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m fires_gdf_reduced \u001b[38;5;241m=\u001b[39m fires_gdf[fires_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(fires_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()[fires_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mindex)]\u001b[38;5;66;03m# save to geojson\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfires_gdf_reduced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/perims/combined_fires_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mYEAR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.geojson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGeoJSON\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jake\\AppData\\Local\\anaconda3\\envs\\firedata\\Lib\\site-packages\\geopandas\\geodataframe.py:1249\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[1;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m \n\u001b[0;32m   1160\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \n\u001b[0;32m   1246\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[1;32m-> 1249\u001b[0m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jake\\AppData\\Local\\anaconda3\\envs\\firedata\\Lib\\site-packages\\geopandas\\io\\file.py:610\u001b[0m, in \u001b[0;36m_to_file\u001b[1;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 610\u001b[0m     \u001b[43m_to_file_fiona\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    612\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jake\\AppData\\Local\\anaconda3\\envs\\firedata\\Lib\\site-packages\\geopandas\\io\\file.py:638\u001b[0m, in \u001b[0;36m_to_file_fiona\u001b[1;34m(df, filename, driver, schema, crs, mode, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m crs:\n\u001b[0;32m    637\u001b[0m     crs_wkt \u001b[38;5;241m=\u001b[39m crs\u001b[38;5;241m.\u001b[39mto_wkt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWKT1_GDAL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 638\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfiona\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs_wkt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs_wkt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m colxn:\n\u001b[0;32m    641\u001b[0m     colxn\u001b[38;5;241m.\u001b[39mwriterecords(df\u001b[38;5;241m.\u001b[39miterfeatures())\n",
      "File \u001b[1;32mc:\\Users\\Jake\\AppData\\Local\\anaconda3\\envs\\firedata\\Lib\\site-packages\\fiona\\env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jake\\AppData\\Local\\anaconda3\\envs\\firedata\\Lib\\site-packages\\fiona\\__init__.py:316\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    306\u001b[0m         path,\n\u001b[0;32m    307\u001b[0m         mode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    314\u001b[0m     )\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrs_wkt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs_wkt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode string must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jake\\AppData\\Local\\anaconda3\\envs\\firedata\\Lib\\site-packages\\fiona\\collection.py:246\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n\u001b[1;32m--> 246\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:1110\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:1111\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:179\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: Failed to create GeoJSON datasource: data/perims/combined_fires_2020.geojson: data/perims/combined_fires_2020.geojson: No such file or directory"
     ]
    }
   ],
   "source": [
    "# drop everything that does not have at least 2 Id in fires_gdf\n",
    "fires_gdf_reduced = fires_gdf[fires_gdf['Id'].isin(fires_gdf['Id'].value_counts()[fires_gdf['Id'].value_counts() > 1].index)]# save to geojson\n",
    "fires_gdf_reduced.to_file(f\"data/perims/combined_fires_{YEAR}.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download daily and final perims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import datetime\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Define the geometry for contiguous USA\n",
    "usa_coords = [\n",
    "    [-125.1803892906456, 35.26328285844432],\n",
    "    [-117.08916345892665, 33.2311514593429],\n",
    "    [-114.35640058749676, 32.92199940444295],\n",
    "    [-110.88773544819885, 31.612036247094473],\n",
    "    [-108.91086200144109, 31.7082477979397],\n",
    "    [-106.80030780089378, 32.42079476218232],\n",
    "    [-103.63413436750255, 29.786401496314422],\n",
    "    [-101.87558377066483, 30.622527701868453],\n",
    "    [-99.40039768482492, 28.04018292597704],\n",
    "    [-98.69085295525215, 26.724810345780593],\n",
    "    [-96.42355704777482, 26.216515704595633],\n",
    "    [-80.68508661702214, 24.546812350183075],\n",
    "    [-75.56173032587596, 26.814533788629998],\n",
    "    [-67.1540159827795, 44.40095539443753],\n",
    "    [-68.07548734644243, 46.981170472447374],\n",
    "    [-69.17500995805074, 46.98158998130476],\n",
    "    [-70.7598785138901, 44.87172183866657],\n",
    "    [-74.84994741250935, 44.748084983808],\n",
    "    [-77.62168256782745, 43.005725611950055],\n",
    "    [-82.45987924104175, 41.41068867019324],\n",
    "    [-83.38318501671864, 42.09979904377044],\n",
    "    [-82.5905167831457, 45.06163491639556],\n",
    "    [-84.83301910769038, 46.83552648258547],\n",
    "    [-88.26350848510909, 48.143646480291835],\n",
    "    [-90.06706251069104, 47.553445811024204],\n",
    "    [-95.03745451438925, 48.9881557770297],\n",
    "    [-98.45773319567587, 48.94699366043251],\n",
    "    [-101.7018751401119, 48.98284560308372],\n",
    "    [-108.43164852530356, 48.81973606668503],\n",
    "    [-115.07339190755627, 48.93699058308441],\n",
    "    [-121.82530604190744, 48.9830983403776],\n",
    "    [-122.22085227110232, 48.63535795404536],\n",
    "    [-124.59504332589562, 47.695726563030405],\n",
    "    [-125.1803892906456, 35.26328285844432]\n",
    "]\n",
    "\n",
    "def create_usa_geometry():\n",
    "    \"\"\"Create an Earth Engine geometry object for the contiguous USA.\"\"\"\n",
    "    return ee.Geometry.Polygon([usa_coords])\n",
    "\n",
    "def compute_area(feature):\n",
    "    \"\"\"Compute the area of a feature and set it as a property.\"\"\"\n",
    "    return feature.set({'area': feature.area()})\n",
    "\n",
    "def compute_centroid(feature):\n",
    "    \"\"\"Compute the centroid coordinates of a feature and set them as properties.\"\"\"\n",
    "    centroid = feature.geometry().centroid().coordinates()\n",
    "    return feature.set({\n",
    "        'lon': centroid.get(0),\n",
    "        'lat': centroid.get(1)\n",
    "    })\n",
    "\n",
    "def ee_featurecollection_to_gdf(fc):\n",
    "    \"\"\"Convert Earth Engine FeatureCollection to GeoPandas DataFrame.\"\"\"\n",
    "    features = fc.getInfo()['features']\n",
    "    \n",
    "    # Extract the geometry and properties from each feature\n",
    "    geometries = []\n",
    "    properties = []\n",
    "    \n",
    "    for feature in features:\n",
    "        # Convert GEE geometry to Shapely geometry\n",
    "        geom = feature['geometry']\n",
    "        if geom['type'] == 'Polygon':\n",
    "            geometry = Polygon(geom['coordinates'][0])\n",
    "        else:\n",
    "            # Handle other geometry types if needed\n",
    "            continue\n",
    "            \n",
    "        geometries.append(geometry)\n",
    "        properties.append(feature['properties'])\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    df = pd.DataFrame(properties)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Convert area to numeric\n",
    "    if 'area' in gdf.columns:\n",
    "        gdf['area'] = pd.to_numeric(gdf['area'])\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def get_daily_fires(year, min_size=1e7, region=None):\n",
    "    \"\"\"\n",
    "    Get daily fire perimeters from the GlobFire database.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to get fires for\n",
    "        min_size (float): Minimum fire size in square meters\n",
    "        region (ee.Geometry, optional): Region to filter fires\n",
    "    \"\"\"\n",
    "    if region is None:\n",
    "        region = create_usa_geometry()\n",
    "    \n",
    "    collection_name = f'JRC/GWIS/GlobFire/v2/DailyPerimeters/{year}'\n",
    "    \n",
    "    try:\n",
    "        polygons = (ee.FeatureCollection(collection_name)\n",
    "                   .filterBounds(region))\n",
    "        \n",
    "        polygons = polygons.map(compute_area)\n",
    "        polygons = (polygons\n",
    "                   .filter(ee.Filter.gt('area', min_size))\n",
    "                   .filter(ee.Filter.lt('area', 1e20)))\n",
    "        \n",
    "        polygons = polygons.map(compute_centroid)\n",
    "        \n",
    "        gdf = ee_featurecollection_to_gdf(polygons)\n",
    "        \n",
    "        if not gdf.empty:\n",
    "            gdf['source'] = 'daily'\n",
    "            # Convert IDate to datetime directly for each row\n",
    "            gdf['date'] = pd.to_datetime(gdf['IDate'], unit='ms')\n",
    "            # For daily perimeters, end_date is same as start date\n",
    "            gdf['end_date'] = gdf['date']\n",
    "        \n",
    "        return gdf\n",
    "        \n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(f\"Error accessing daily collection for {year}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_final_fires(year, min_size=1e7, region=None):\n",
    "    \"\"\"\n",
    "    Get final fire perimeters from the GlobFire database.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to get fires for\n",
    "        min_size (float): Minimum fire size in square meters\n",
    "        region (ee.Geometry, optional): Region to filter fires\n",
    "    \"\"\"\n",
    "    if region is None:\n",
    "        region = create_usa_geometry()\n",
    "    \n",
    "    start_date = ee.Date(f'{year}-01-01')\n",
    "    end_date = ee.Date(f'{year}-12-31')\n",
    "    \n",
    "    try:\n",
    "        polygons = (ee.FeatureCollection('JRC/GWIS/GlobFire/v2/FinalPerimeters')\n",
    "                   .filter(ee.Filter.gt('IDate', start_date.millis()))\n",
    "                   .filter(ee.Filter.lt('IDate', end_date.millis()))\n",
    "                   .filterBounds(region))\n",
    "        \n",
    "        polygons = polygons.map(compute_area)\n",
    "        polygons = (polygons\n",
    "                   .filter(ee.Filter.gt('area', min_size))\n",
    "                   .filter(ee.Filter.lt('area', 1e20)))\n",
    "        \n",
    "        polygons = polygons.map(compute_centroid)\n",
    "        \n",
    "        gdf = ee_featurecollection_to_gdf(polygons)\n",
    "        \n",
    "        if not gdf.empty:\n",
    "            gdf['source'] = 'final'\n",
    "            # Convert IDate and FDate to datetime for each row\n",
    "            gdf['date'] = pd.to_datetime(gdf['IDate'], unit='ms')\n",
    "            gdf['end_date'] = pd.to_datetime(gdf['FDate'], unit='ms')\n",
    "        \n",
    "        return gdf\n",
    "        \n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(f\"Error accessing final perimeters for {year}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_combined_fires(year, min_size=1e7, region=None):\n",
    "    \"\"\"\n",
    "    Get both daily and final fire perimeters and combine them based on Id.\n",
    "    \n",
    "    Args:\n",
    "        year (str): The year to get fires for\n",
    "        min_size (float): Minimum fire size in square meters\n",
    "        region (ee.Geometry, optional): Region to filter fires\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (combined_gdf, daily_gdf, final_gdf)\n",
    "    \"\"\"\n",
    "    daily_gdf = get_daily_fires(year, min_size, region)\n",
    "    final_gdf = get_final_fires(year, min_size, region)\n",
    "    \n",
    "    if daily_gdf is None and final_gdf is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Ensure we have dataframes to work with\n",
    "    if daily_gdf is None:\n",
    "        daily_gdf = gpd.GeoDataFrame()\n",
    "    if final_gdf is None:\n",
    "        final_gdf = gpd.GeoDataFrame()\n",
    "    \n",
    "    # Convert timestamps consistently\n",
    "    for gdf in [daily_gdf, final_gdf]:\n",
    "        if not gdf.empty:\n",
    "            # Convert all timestamp fields to numeric if they aren't already\n",
    "            for col in ['IDate', 'FDate']:\n",
    "                if col in gdf.columns:\n",
    "                    gdf[col] = pd.to_numeric(gdf[col])\n",
    "            for col in ['FDate']:\n",
    "                if col in gdf.columns:\n",
    "                    gdf[col] = gdf['end_date']\n",
    "    \n",
    "    # Get unique fire IDs\n",
    "    all_ids = pd.concat([\n",
    "        daily_gdf['Id'] if not daily_gdf.empty else pd.Series(dtype=int),\n",
    "        final_gdf['Id'] if not final_gdf.empty else pd.Series(dtype=int)\n",
    "    ]).unique()\n",
    "    \n",
    "    combined_data = []\n",
    "    \n",
    "    for fire_id in all_ids:\n",
    "        # Get daily perimeters for this fire\n",
    "        daily_fire = daily_gdf[daily_gdf['Id'] == fire_id] if not daily_gdf.empty else None\n",
    "        # Get final perimeter for this fire\n",
    "        final_fire = final_gdf[final_gdf['Id'] == fire_id] if not final_gdf.empty else None\n",
    "        \n",
    "        if daily_fire is not None and not daily_fire.empty:\n",
    "            # Add all daily perimeters\n",
    "            combined_data.append(daily_fire)\n",
    "        \n",
    "        if final_fire is not None and not final_fire.empty:\n",
    "            # Add final perimeter\n",
    "            combined_data.append(final_fire)\n",
    "    \n",
    "    if not combined_data:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_gdf = pd.concat(combined_data, ignore_index=True)\n",
    "    \n",
    "    # Sort by Id and date for consistency\n",
    "    combined_gdf = combined_gdf.sort_values(['Id', 'date'])\n",
    "    \n",
    "    return combined_gdf, daily_gdf, final_gdf\n",
    "\n",
    "def analyze_fires(gdf):\n",
    "    \"\"\"\n",
    "    Perform basic analysis on fire perimeters.\n",
    "    \"\"\"\n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Basic statistics\n",
    "    stats = {\n",
    "        'total_fires': len(gdf),\n",
    "        'unique_fires': gdf['Id'].nunique(),\n",
    "        'total_area_km2': gdf['area'].sum() / 1e6,\n",
    "        'mean_area_km2': gdf['area'].mean() / 1e6,\n",
    "        'max_area_km2': gdf['area'].max() / 1e6,\n",
    "        'date_range': f\"{gdf['date'].min()} to {gdf['end_date'].max()}\"\n",
    "    }\n",
    "    \n",
    "    # Add source-specific counts\n",
    "    if 'source' in gdf.columns:\n",
    "        source_counts = gdf['source'].value_counts()\n",
    "        for source in source_counts.index:\n",
    "            stats[f'{source}_fires'] = source_counts[source]\n",
    "            \n",
    "        # Add counts of fires with both daily and final perimeters\n",
    "        fires_with_both = (gdf.groupby('Id')['source']\n",
    "                          .nunique()\n",
    "                          .where(lambda x: x > 1)\n",
    "                          .count())\n",
    "        stats['fires_with_both_perims'] = fires_with_both\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Example usage\n",
    "YEAR = \"2020\"\n",
    "MIN_SIZE = 1e7  # 10 square kilometers\n",
    "\n",
    "# Get both daily and final perimeters\n",
    "combined_gdf, daily_gdf, final_gdf = get_combined_fires(YEAR, MIN_SIZE)\n",
    "\n",
    "if combined_gdf is not None:\n",
    "    print(f\"\\nAnalysis Results for {YEAR}:\")\n",
    "    \n",
    "    print(\"\\nCombined Perimeters:\")\n",
    "    combined_stats = analyze_fires(combined_gdf)\n",
    "    for key, value in combined_stats.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    if daily_gdf is not None:\n",
    "        print(\"\\nDaily Perimeters:\")\n",
    "        daily_stats = analyze_fires(daily_gdf)\n",
    "        for key, value in daily_stats.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    if final_gdf is not None:\n",
    "        print(\"\\nFinal Perimeters:\")\n",
    "        final_stats = analyze_fires(final_gdf)\n",
    "        for key, value in final_stats.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Temporal distribution\n",
    "    print(\"\\nFires by month:\")\n",
    "    monthly_counts = combined_gdf.groupby([combined_gdf['date'].dt.month, 'source']).size().unstack(fill_value=0)\n",
    "    print(monthly_counts)\n",
    "\n",
    "# drop everything that does not have at least 2 Id in combined_gdf\n",
    "combined_gdf_reduced = combined_gdf[combined_gdf['Id'].isin(combined_gdf['Id'].value_counts()[combined_gdf['Id'].value_counts() > 1].index)]# save to geojson\n",
    "combined_gdf_reduced.to_file(f\"data/perims/combined_fires_{YEAR}.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_perimeters(daily_gdf, final_gdf):\n",
    "    \"\"\"\n",
    "    Create a dataframe containing only fire perimeters that appear in both daily and final datasets.\n",
    "    \n",
    "    Args:\n",
    "        daily_gdf (GeoDataFrame): DataFrame containing daily fire perimeters\n",
    "        final_gdf (GeoDataFrame): DataFrame containing final fire perimeters\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: Combined DataFrame containing only fires that appear in both datasets\n",
    "    \"\"\"\n",
    "    # Handle cases where either dataframe is None or empty\n",
    "    if daily_gdf is None or final_gdf is None or daily_gdf.empty or final_gdf.empty:\n",
    "        return None\n",
    "    \n",
    "    # Get IDs that appear in both datasets\n",
    "    daily_ids = set(daily_gdf['Id'].unique())\n",
    "    final_ids = set(final_gdf['Id'].unique())\n",
    "    matching_ids = daily_ids.intersection(final_ids)\n",
    "    \n",
    "    if not matching_ids:\n",
    "        return None\n",
    "    \n",
    "    # Filter both dataframes for matching IDs\n",
    "    daily_matches = daily_gdf[daily_gdf['Id'].isin(matching_ids)].copy()\n",
    "    final_matches = final_gdf[final_gdf['Id'].isin(matching_ids)].copy()\n",
    "    \n",
    "    # Combine the filtered dataframes\n",
    "    matching_perims = pd.concat([daily_matches, final_matches], ignore_index=True)\n",
    "    \n",
    "    # Sort by Id and date for consistency\n",
    "    matching_perims = matching_perims.sort_values(['Id', 'date'])\n",
    "    \n",
    "    # Add some useful metadata\n",
    "    matching_perims['match_type'] = 'both_sources'\n",
    "    \n",
    "    return matching_perims\n",
    "\n",
    "# Example usage in main script:\n",
    "if __name__ == \"__main__\":\n",
    "    YEAR = \"2020\"\n",
    "    MIN_SIZE = 1e7  # 10 square kilometers\n",
    "    \n",
    "    # Get fire perimeters\n",
    "    # combined_gdf, daily_gdf, final_gdf = get_combined_fires(YEAR, MIN_SIZE)\n",
    "    \n",
    "    # Get matching perimeters\n",
    "    matching_perims = get_matching_perimeters(daily_gdf, final_gdf)\n",
    "    \n",
    "    if matching_perims is not None:\n",
    "        print(\"\\nMatching Perimeters Analysis:\")\n",
    "        matching_stats = analyze_fires(matching_perims)\n",
    "        for key, value in matching_stats.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "            \n",
    "        # Additional statistics specific to matching perimeters\n",
    "        print(\"\\nDetailed Matching Statistics:\")\n",
    "        unique_matches = matching_perims['Id'].nunique()\n",
    "        print(f\"Number of unique fires with both daily and final perimeters: {unique_matches}\")\n",
    "        \n",
    "        # Calculate average number of daily perims per fire\n",
    "        daily_counts = matching_perims[matching_perims['source'] == 'daily'].groupby('Id').size()\n",
    "        print(f\"Average daily perimeters per fire: {daily_counts.mean():.1f}\")\n",
    "        print(f\"Max daily perimeters for a single fire: {daily_counts.max()}\")\n",
    "        \n",
    "        # Show distribution of time spans\n",
    "        time_spans = matching_perims.groupby('Id').agg({\n",
    "            'date': 'min',\n",
    "            'end_date': 'max'\n",
    "        })\n",
    "        time_spans['duration_days'] = (time_spans['end_date'] - time_spans['date']).dt.total_seconds() / (24*3600)\n",
    "        print(f\"\\nFire duration statistics (days):\")\n",
    "        print(f\"Mean duration: {time_spans['duration_days'].mean():.1f}\")\n",
    "        print(f\"Median duration: {time_spans['duration_days'].median():.1f}\")\n",
    "        print(f\"Max duration: {time_spans['duration_days'].max():.1f}\")\n",
    "    else:\n",
    "        print(\"\\nNo matching perimeters found between daily and final datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_gdf[combined_gdf.Id == 25294714]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show Ids that match between daily and final as keys in a dict, with the number of times they appear in daily source as values\n",
    "fires = {}\n",
    "for i in final_gdf['Id']:\n",
    "    if i in daily_gdf['Id'].values:\n",
    "        fires[i] = daily_gdf[daily_gdf['Id'] == i].shape[0]\n",
    "\n",
    "fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the perims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "def calculate_area_km2(geometry, lat, lon):\n",
    "    \"\"\"\n",
    "    Calculate area in square kilometers using an equal area projection.\n",
    "    \n",
    "    Args:\n",
    "        geometry: Shapely geometry\n",
    "        lat: Latitude of centroid for projection center\n",
    "        lon: Longitude of centroid for projection center\n",
    "    \n",
    "    Returns:\n",
    "        float: Area in square kilometers\n",
    "    \"\"\"\n",
    "    # Create a temporary GeoDataFrame with the geometry\n",
    "    temp_gdf = gpd.GeoDataFrame(geometry=[geometry], crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Project to an equal area projection centered on the area of interest\n",
    "    proj_string = f\"+proj=aea +lat_1={lat-5} +lat_2={lat+5} +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\n",
    "    temp_gdf = temp_gdf.to_crs(proj_string)\n",
    "    \n",
    "    # Calculate area in km²\n",
    "    return temp_gdf.area.iloc[0] / 1e6\n",
    "\n",
    "def get_polygon_coords(geometry):\n",
    "    \"\"\"\n",
    "    Extract coordinates from either a Polygon or MultiPolygon.\n",
    "    Returns a list of coordinate arrays, one per ring.\n",
    "    \"\"\"\n",
    "    coords_list = []\n",
    "    \n",
    "    if isinstance(geometry, MultiPolygon):\n",
    "        for polygon in geometry.geoms:\n",
    "            coords_list.append(np.array(polygon.exterior.coords))\n",
    "            for interior in polygon.interiors:\n",
    "                coords_list.append(np.array(interior.coords))\n",
    "    elif isinstance(geometry, Polygon):\n",
    "        coords_list.append(np.array(geometry.exterior.coords))\n",
    "        for interior in geometry.interiors:\n",
    "            coords_list.append(np.array(interior.coords))\n",
    "    \n",
    "    return coords_list\n",
    "\n",
    "def animate_fire_progression(gdf, fire_id, interval=500):\n",
    "    \"\"\"\n",
    "    Create an animated visualization of cumulative fire progression.\n",
    "    \"\"\"\n",
    "    # Filter for the specific fire and sort by date\n",
    "    fire_perimeters = gdf[gdf['Id'] == fire_id].sort_values('IDate')\n",
    "    \n",
    "    # Pre-compute cumulative geometries\n",
    "    cumulative_geometries = []\n",
    "    current_geometry = None\n",
    "    \n",
    "    for idx, row in fire_perimeters.iterrows():\n",
    "        if current_geometry is None:\n",
    "            current_geometry = row.geometry\n",
    "        else:\n",
    "            current_geometry = unary_union([current_geometry, row.geometry])\n",
    "        cumulative_geometries.append(current_geometry)\n",
    "    \n",
    "    # Get centroid of final perimeter for area calculation\n",
    "    final_centroid = cumulative_geometries[-1].centroid\n",
    "    \n",
    "    # Create GeoDataFrame with cumulative geometries\n",
    "    cumulative_gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            'geometry': cumulative_geometries,\n",
    "            'IDate': fire_perimeters['IDate'].values\n",
    "        },\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    # Calculate areas using the centroid-based projection\n",
    "    cumulative_gdf['area_km2'] = [\n",
    "        calculate_area_km2(geom, final_centroid.y, final_centroid.x)\n",
    "        for geom in cumulative_gdf.geometry\n",
    "    ]\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Set consistent plot limits\n",
    "    total_bounds = cumulative_gdf.total_bounds\n",
    "    padding = 0.1\n",
    "    width = total_bounds[2] - total_bounds[0]\n",
    "    height = total_bounds[3] - total_bounds[1]\n",
    "    ax.set_xlim(total_bounds[0] - width * padding, \n",
    "                total_bounds[2] + width * padding)\n",
    "    ax.set_ylim(total_bounds[1] - height * padding, \n",
    "                total_bounds[3] + height * padding)\n",
    "    \n",
    "    # Create lists to store all lines and fills\n",
    "    lines = []\n",
    "    fills = []\n",
    "    \n",
    "    # Initialize with empty data\n",
    "    for i in range(10):\n",
    "        line, = ax.plot([], [], 'r-', lw=2)\n",
    "        fill = ax.fill([], [], 'r', alpha=0.3)[0]\n",
    "        lines.append(line)\n",
    "        fills.append(fill)\n",
    "    \n",
    "    area_text = ax.text(0.02, 0.98, '', transform=ax.transAxes, \n",
    "                       verticalalignment='top')\n",
    "    title = ax.set_title('')\n",
    "    \n",
    "    # Format dates for display\n",
    "    dates = pd.to_datetime(cumulative_gdf['IDate'], unit='ms')\n",
    "    date_strings = dates.dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    def init():\n",
    "        for line, fill in zip(lines, fills):\n",
    "            line.set_data([], [])\n",
    "            fill.set_xy(np.empty((0, 2)))\n",
    "        area_text.set_text('')\n",
    "        return lines + fills + [area_text, title]\n",
    "    \n",
    "    def animate(frame):\n",
    "        perimeter = cumulative_gdf.iloc[frame]\n",
    "        all_coords = get_polygon_coords(perimeter.geometry)\n",
    "        \n",
    "        for i, coords in enumerate(all_coords):\n",
    "            if i < len(lines):\n",
    "                lines[i].set_data(coords[:, 0], coords[:, 1])\n",
    "                fills[i].set_xy(coords)\n",
    "            else:\n",
    "                line, = ax.plot([], [], 'r-', lw=2)\n",
    "                fill = ax.fill([], [], 'r', alpha=0.3)[0]\n",
    "                lines.append(line)\n",
    "                fills.append(fill)\n",
    "                lines[i].set_data(coords[:, 0], coords[:, 1])\n",
    "                fills[i].set_xy(coords)\n",
    "        \n",
    "        for i in range(len(all_coords), len(lines)):\n",
    "            lines[i].set_data([], [])\n",
    "            fills[i].set_xy(np.empty((0, 2)))\n",
    "        \n",
    "        area_text.set_text(f'Area: {perimeter.area_km2:.2f} km²')\n",
    "        title.set_text(f'Fire ID {fire_id} - {date_strings.iloc[frame]}')\n",
    "        \n",
    "        return lines + fills + [area_text, title]\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                 frames=len(cumulative_gdf),\n",
    "                                 interval=interval, blit=True)\n",
    "    \n",
    "    html = anim.to_jshtml()\n",
    "    plt.close()\n",
    "    \n",
    "    return HTML(html)\n",
    "\n",
    "def create_fire_summary(gdf, fire_id):\n",
    "    \"\"\"\n",
    "    Create a summary of cumulative fire progression.\n",
    "    \"\"\"\n",
    "    fire_perimeters = gdf[gdf['Id'] == fire_id].sort_values('IDate')\n",
    "    \n",
    "    # Calculate cumulative geometries\n",
    "    cumulative_geometries = []\n",
    "    current_geometry = None\n",
    "    \n",
    "    for idx, row in fire_perimeters.iterrows():\n",
    "        if current_geometry is None:\n",
    "            current_geometry = row.geometry\n",
    "        else:\n",
    "            current_geometry = unary_union([current_geometry, row.geometry])\n",
    "        cumulative_geometries.append(current_geometry)\n",
    "    \n",
    "    # Get centroid of final perimeter for area calculation\n",
    "    final_centroid = cumulative_geometries[-1].centroid\n",
    "    \n",
    "    # Calculate areas\n",
    "    areas = [\n",
    "        calculate_area_km2(geom, final_centroid.y, final_centroid.x)\n",
    "        for geom in cumulative_geometries\n",
    "    ]\n",
    "    \n",
    "    # Convert dates\n",
    "    dates = pd.to_datetime(fire_perimeters['IDate'], unit='ms')\n",
    "    \n",
    "    summary = {\n",
    "        'start_date': dates.min(),\n",
    "        'end_date': dates.max(),\n",
    "        'duration_days': (dates.max() - dates.min()).days,\n",
    "        'num_updates': len(fire_perimeters),\n",
    "        'initial_area_km2': areas[0],\n",
    "        'final_area_km2': areas[-1],\n",
    "        'total_growth_km2': areas[-1] - areas[0],\n",
    "        'average_daily_growth_km2': (areas[-1] - areas[0]) / max((dates.max() - dates.min()).days, 1)\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Create and display the animation\n",
    "animation = animate_fire_progression(fires_gdf, 24332801)\n",
    "display(animation)\n",
    "\n",
    "# Get summary statistics\n",
    "summary = create_fire_summary(fires_gdf, 24332801)\n",
    "print(\"\\nFire Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "def calculate_area_km2(geometry, lat, lon):\n",
    "    \"\"\"\n",
    "    Calculate area in square kilometers using an equal area projection.\n",
    "    \"\"\"\n",
    "    temp_gdf = gpd.GeoDataFrame(geometry=[geometry], crs=\"EPSG:4326\")\n",
    "    proj_string = f\"+proj=aea +lat_1={lat-5} +lat_2={lat+5} +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\n",
    "    temp_gdf = temp_gdf.to_crs(proj_string)\n",
    "    return temp_gdf.area.iloc[0] / 1e6\n",
    "\n",
    "def get_polygon_coords(geometry):\n",
    "    \"\"\"\n",
    "    Extract coordinates from either a Polygon or MultiPolygon.\n",
    "    \"\"\"\n",
    "    coords_list = []\n",
    "    if isinstance(geometry, MultiPolygon):\n",
    "        for polygon in geometry.geoms:\n",
    "            coords_list.append(np.array(polygon.exterior.coords))\n",
    "            for interior in polygon.interiors:\n",
    "                coords_list.append(np.array(interior.coords))\n",
    "    elif isinstance(geometry, Polygon):\n",
    "        coords_list.append(np.array(geometry.exterior.coords))\n",
    "        for interior in geometry.interiors:\n",
    "            coords_list.append(np.array(interior.coords))\n",
    "    return coords_list\n",
    "\n",
    "def animate_fire_progression(gdf, fire_id, interval=500):\n",
    "    \"\"\"\n",
    "    Create an animated visualization of fire progression with final perimeter.\n",
    "    \"\"\"\n",
    "    # Split daily and final perimeters\n",
    "    daily_perims = gdf[(gdf['Id'] == fire_id) & (gdf['source'] == 'daily')].sort_values('date')\n",
    "    final_perim = gdf[(gdf['Id'] == fire_id) & (gdf['source'] == 'final')]\n",
    "    \n",
    "    # Pre-compute daily cumulative geometries\n",
    "    cumulative_geometries = []\n",
    "    current_geometry = None\n",
    "    \n",
    "    for idx, row in daily_perims.iterrows():\n",
    "        if current_geometry is None:\n",
    "            current_geometry = row.geometry\n",
    "        else:\n",
    "            current_geometry = unary_union([current_geometry, row.geometry])\n",
    "        cumulative_geometries.append(current_geometry)\n",
    "    \n",
    "    # Add final perimeter as the last frame if it exists\n",
    "    if not final_perim.empty:\n",
    "        cumulative_geometries.append(final_perim.iloc[0].geometry)\n",
    "        # For daily perimeters, use 'date', for final perimeter use 'end_date'\n",
    "        dates = pd.concat([\n",
    "            daily_perims['date'],\n",
    "            pd.Series([final_perim.iloc[0]['end_date']])\n",
    "        ]).reset_index(drop=True)\n",
    "    else:\n",
    "        dates = daily_perims['date'].reset_index(drop=True)\n",
    "    \n",
    "    # Get centroid of final perimeter for area calculation\n",
    "    final_centroid = cumulative_geometries[-1].centroid\n",
    "    \n",
    "    # Create GeoDataFrame with cumulative geometries\n",
    "    cumulative_gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            'geometry': cumulative_geometries,\n",
    "            'date': dates,\n",
    "            'is_final': [False] * len(daily_perims) + [True] * (1 if not final_perim.empty else 0)\n",
    "        },\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    # Calculate areas\n",
    "    cumulative_gdf['area_km2'] = [\n",
    "        calculate_area_km2(geom, final_centroid.y, final_centroid.x)\n",
    "        for geom in cumulative_gdf.geometry\n",
    "    ]\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Set consistent plot limits\n",
    "    total_bounds = cumulative_gdf.total_bounds\n",
    "    padding = 0.1\n",
    "    width = total_bounds[2] - total_bounds[0]\n",
    "    height = total_bounds[3] - total_bounds[1]\n",
    "    ax.set_xlim(total_bounds[0] - width * padding, \n",
    "                total_bounds[2] + width * padding)\n",
    "    ax.set_ylim(total_bounds[1] - height * padding, \n",
    "                total_bounds[3] + height * padding)\n",
    "    \n",
    "    # Create lists to store all lines and fills\n",
    "    lines = []\n",
    "    fills = []\n",
    "    \n",
    "    # Initialize with empty data\n",
    "    for i in range(10):\n",
    "        line, = ax.plot([], [], 'r-', lw=2)\n",
    "        fill = ax.fill([], [], 'r', alpha=0.3)[0]\n",
    "        lines.append(line)\n",
    "        fills.append(fill)\n",
    "    \n",
    "    area_text = ax.text(0.02, 0.98, '', transform=ax.transAxes, \n",
    "                       verticalalignment='top')\n",
    "    title = ax.set_title('')\n",
    "    \n",
    "    def init():\n",
    "        for line, fill in zip(lines, fills):\n",
    "            line.set_data([], [])\n",
    "            fill.set_xy(np.empty((0, 2)))\n",
    "        area_text.set_text('')\n",
    "        return lines + fills + [area_text, title]\n",
    "    \n",
    "    def animate(frame):\n",
    "        perimeter = cumulative_gdf.iloc[frame]\n",
    "        all_coords = get_polygon_coords(perimeter.geometry)\n",
    "        \n",
    "        # Use different colors for final perimeter\n",
    "        color = 'blue' if perimeter.is_final else 'r'\n",
    "        alpha = 0.5 if perimeter.is_final else 0.3\n",
    "        \n",
    "        for i, coords in enumerate(all_coords):\n",
    "            if i < len(lines):\n",
    "                lines[i].set_color(color)\n",
    "                lines[i].set_data(coords[:, 0], coords[:, 1])\n",
    "                fills[i].set_facecolor(color)\n",
    "                fills[i].set_alpha(alpha)\n",
    "                fills[i].set_xy(coords)\n",
    "            else:\n",
    "                line, = ax.plot([], [], f'{color}-', lw=2)\n",
    "                fill = ax.fill([], [], color, alpha=alpha)[0]\n",
    "                lines.append(line)\n",
    "                fills.append(fill)\n",
    "                lines[i].set_data(coords[:, 0], coords[:, 1])\n",
    "                fills[i].set_xy(coords)\n",
    "        \n",
    "        for i in range(len(all_coords), len(lines)):\n",
    "            lines[i].set_data([], [])\n",
    "            fills[i].set_xy(np.empty((0, 2)))\n",
    "        \n",
    "        # Update area text\n",
    "        area_text.set_text(f'Area: {perimeter.area_km2:.2f} km²')\n",
    "        \n",
    "        # Update title with date and type\n",
    "        perim_type = \"Final Perimeter\" if perimeter.is_final else \"Daily Perimeter\"\n",
    "        display_date = perimeter.date.strftime(\"%Y-%m-%d\")\n",
    "        title.set_text(f'Fire ID {fire_id} - {display_date} ({perim_type})')\n",
    "        \n",
    "        return lines + fills + [area_text, title]\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                 frames=len(cumulative_gdf),\n",
    "                                 interval=interval, blit=True)\n",
    "    \n",
    "    html = anim.to_jshtml()\n",
    "    plt.close()\n",
    "    \n",
    "    return HTML(html)\n",
    "\n",
    "def create_fire_summary(gdf, fire_id):\n",
    "    \"\"\"\n",
    "    Create a summary of fire progression including both daily and final perimeters.\n",
    "    \"\"\"\n",
    "    # Get daily perimeters and optional final perimeter\n",
    "    daily_perims = gdf[(gdf['Id'] == fire_id) & (gdf['source'] == 'daily')].sort_values('date')\n",
    "    final_perim = gdf[(gdf['Id'] == fire_id) & (gdf['source'] == 'final')]\n",
    "    \n",
    "    # Calculate cumulative geometries for daily progression\n",
    "    cumulative_geometries = []\n",
    "    current_geometry = None\n",
    "    \n",
    "    for idx, row in daily_perims.iterrows():\n",
    "        if current_geometry is None:\n",
    "            current_geometry = row.geometry\n",
    "        else:\n",
    "            current_geometry = unary_union([current_geometry, row.geometry])\n",
    "        cumulative_geometries.append(current_geometry)\n",
    "    \n",
    "    # Add final perimeter if available\n",
    "    if not final_perim.empty:\n",
    "        final_geometry = final_perim.iloc[0].geometry\n",
    "        final_date = final_perim.iloc[0].end_date\n",
    "    else:\n",
    "        final_geometry = cumulative_geometries[-1] if cumulative_geometries else None\n",
    "        final_date = daily_perims.iloc[-1].end_date if not daily_perims.empty else None\n",
    "    \n",
    "    if not cumulative_geometries and final_geometry is None:\n",
    "        return None\n",
    "    \n",
    "    # Get centroid for area calculations\n",
    "    centroid = final_geometry.centroid if final_geometry else cumulative_geometries[-1].centroid\n",
    "    \n",
    "    # Calculate areas\n",
    "    daily_areas = [\n",
    "        calculate_area_km2(geom, centroid.y, centroid.x)\n",
    "        for geom in cumulative_geometries\n",
    "    ]\n",
    "    \n",
    "    if final_geometry:\n",
    "        final_area = calculate_area_km2(final_geometry, centroid.y, centroid.x)\n",
    "    else:\n",
    "        final_area = daily_areas[-1] if daily_areas else None\n",
    "    \n",
    "    # Get dates\n",
    "    start_date = daily_perims.iloc[0].end_date if not daily_perims.empty else final_date\n",
    "    \n",
    "    summary = {\n",
    "        'start_date': start_date,\n",
    "        'end_date': final_date,\n",
    "        'duration_days': (final_date - start_date).days,\n",
    "        'num_daily_updates': len(daily_perims),\n",
    "        'has_final_perimeter': not final_perim.empty,\n",
    "        'initial_area_km2': daily_areas[0] if daily_areas else final_area,\n",
    "        'final_area_km2': final_area,\n",
    "        'total_growth_km2': final_area - daily_areas[0] if daily_areas else 0,\n",
    "        'average_daily_growth_km2': (final_area - daily_areas[0]) / max((final_date - start_date).days, 1) if daily_areas else 0\n",
    "    }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display the animation\n",
    "# animation = None\n",
    "animation = animate_fire_progression(combined_gdf, 20778153)\n",
    "display(animation)\n",
    "\n",
    "# Get summary statistics\n",
    "summary = create_fire_summary(combined_gdf, 20778153)\n",
    "print(\"\\nFire Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop everything that does not have at least 2 Id in combined_gdf\n",
    "combined_gdf_reduced = combined_gdf[combined_gdf['Id'].isin(combined_gdf['Id'].value_counts()[combined_gdf['Id'].value_counts() > 1].index)]# save to geojson\n",
    "combined_gdf_reduced.to_file(f\"data/perims/combined_fires_{YEAR}.geojson\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
